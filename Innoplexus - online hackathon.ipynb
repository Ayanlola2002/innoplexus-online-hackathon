{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div><h1>Innoplexus – Online Hackathon: An Approach to Moral Victory</h1></div><br>\n",
    "\n",
    "<div align=\"justify\">In this notebook I will be sharing my approach to the innoplexus online hackathon hosted by Analytics Vidhya on 25 May 2018. I achieved a score of <b>0.4588</b>, second place on the public leader board. However, as I lost track of time I was one minute to late with this final submission. For that reason, it does not count towards the private leader board scoring.</div><br>\n",
    "\n",
    "<div>– Time is what we have most, but what we use worst – #Aziz Shavershian aka Zyzz</div><br>\n",
    "\n",
    "<div align=\"justify\">I have decided to share my approach because I feel very confident this model would have won the competition, as it comprised only of feature extraction topped with a simple classifier and thus not very prone to be overfitted on the public leader board. Moreover, since the modeling part was so basic (due to time constraints) there is a whole lot of room left for improvement, modeling wise – which might be of interest to you. If so do not hesitate to get back at me!</div><br>\n",
    "\n",
    "<div>Hope you enjoy,</div>\n",
    "\n",
    "<div align=\"right\">By wcools <br> aka Alexander de Leeuw <br> wiljancools@gmail.com</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div><h1>Problem statement</h1></div><br>\n",
    "\n",
    "<div align=\"justify\">As explained on the <a href=\"https://datahack.analyticsvidhya.com/contest/innoplexus-hiring-hackathon\">contest homepage</a>, competitors are asked to come up with a model that can <b>predict for each article which other articles it will cite as a reference.</b></div><br>\n",
    "\n",
    "<div align=\"justify\">Participants are also notified that there are 18 sets of articles, 9 in the training data and 9 in the test data. The test data is further devided into two parts, a public part containing 5 sets and a private part containing 4 sets.</div><br>\n",
    "\n",
    "<div>Also, competitors should keep in mind that:\n",
    "<ul><li>Each set of articles is independent and centred around the same topic e.g. biology</li>\n",
    "<li>Only articles in the same set can be used as a reference.</li>\n",
    "<li>Every article has at least one reference</li></ul></div><br>\n",
    "\n",
    "<div style=\"margin-top:-10px;\" align=\"justify\">The metric used for evaluation is the F1-score weighted by samples: <i> sklearn.metrics.f1_score(y_true, y_pred, average='binary') </i>. What is more, is that the F1-scores are first calculated for each prediction, then averaged per set and then averaged across all sets. This makes a single prediction from a smaller set more important than from a larger set, as every set has the same contribution to the final score.</div><br>\n",
    "\n",
    "<div><h1>Hacking strategy</h1></div><br>\n",
    "    \n",
    "<div align=\"justify\">It is quite astonishing to see that only 50 of the 1863 participants were able to make a significant submission. Which is far below the average of other competitions Analytics Vidhya has hosted, even though the competition lasted 48 hours. This probably has to do with the way the challenge was presented. Observe the target data:</div>\n",
    "\n",
    "||pm_id|ref_list\n",
    "|-:|-:| -:\n",
    "|0|187|['1053', '7500']|\n",
    "|1|15080|[45753]|\n",
    "\n",
    "<br><div align=\"justify\">At first, I had no idea how to tackle this problem. Should it be treated as a multilabel classification, should this be considered a recommender engine. I am still not a 100 per cent certain whether the way I solved it, is the best way. That overwhelming feeling of uncertainty in combination with the text features and confusing evaluation metric might have scared some people away, I think. Anyhow, I believe that this is exactly what makes hackathons challenging and fun.</div><br>\n",
    "\n",
    "<div align=\"justify\">I treated this problem as a binary classification task. With the target variable a boolean <b>is_referenced_flg = True or False</b> and the input data two paired articles and extracted features from these two articles. For training the model I paired all possible articles in each set and checked whether the ref_id was in the ref_list of the pm_id. The previous table thus becomes:</div>\n",
    "\n",
    "||pm_id|ref_id|features|is_referenced_flg\n",
    "|-|-|-|-|-|\n",
    "|0|187|1053| ... |True\n",
    "|1|187|7500| ... |True\n",
    "|2|187|15080| ... |False\n",
    "|3|187|45753| ... |False\n",
    "|4|15080|187| ... |False\n",
    "|5|15080|1053| ... |False\n",
    "|6|15080|7500| ... |False\n",
    "|7|15080|45753| ... |True\n",
    "\n",
    "<br><div align=\"justify\">Using the above data table a classification model can be trained. This model can generate a score (pred_proba) for each paired article. After having used this model for scoring it is then a matter of selecting the best performing article pairs. I used a tren-hold #Mike O'Hearn of 0.5. If an article had no pair scoring higher than 0.5, I selected the pair with the highest score. Following this selection procedure, all chosen reference articles are folded into a list to match the format of the provided target data.</div><br>\n",
    "\n",
    "<div>For example,<br>\n",
    "The following model output:</div>\n",
    "\n",
    "||pm_id|ref_id|features|pred_proba\n",
    "|-|-|-|-|-|\n",
    "|1|210|950| ... |0.4\n",
    "|2|210|1600| ... |0.89\n",
    "|3|210|10200| ... |0.64\n",
    "|4|19000|56000| ... |0.08\n",
    "|5|19000|102000| ... |0.23\n",
    "\n",
    "<br><div>Would generate the following predictions:</div><br>\n",
    "\n",
    "||pm_id|ref_list\n",
    "|-:|-:| -:\n",
    "|0|210|['1600', '10200']|\n",
    "|1|19000|['102000']|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='123'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "\n",
    "[0) Setup](#0)\n",
    "\n",
    "[1) Data exploration](#1)\n",
    "\n",
    "[2) Data wrangling](#2)\n",
    "\n",
    "[3) Feature engineering](#3)\n",
    "\n",
    "> [3.1) Basic feature extraction](#31)\n",
    "\n",
    "> [3.2) Extracting and engineering features from authors](#32)\n",
    "    \n",
    "> [3.3) Extracting and engineering features from text fields](#33)\n",
    "    \n",
    "> [3.4) Combining features](#34)\n",
    " \n",
    "[4) Data selection and partitioning](#4)\n",
    "\n",
    "[5) Baseline modeling](#5)\n",
    "\n",
    "[6) Spotchecking](#6)\n",
    "\n",
    "[7) Submission](#7)\n",
    "\n",
    "[8) Reflection](#8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0) Setup\n",
    "\n",
    "[Back to table of contents](#123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Cools\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Cools\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import some generic libraries\n",
    "import os\n",
    "import ast\n",
    "import time\n",
    "from IPython.display import display, Image\n",
    "from collections import OrderedDict, Counter\n",
    "\n",
    "# Import libraries for data analysis\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import libraries for data visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import libraries for text analysis\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Import machine learning functionalities from sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier, Perceptron, RidgeClassifier, LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB, MultinomialNB\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data and give the variables a more explanatory and consistent name\n",
    "to_rename = {'pmid': 'pm_id',\n",
    "             'article_title': 'title_str',\n",
    "             'abstract': 'abstract_str',\n",
    "             'full_Text': 'text_str',\n",
    "             'author_str': 'authors_str',\n",
    "             'set': 'set_num'}\n",
    "\n",
    "info_train = pd.read_csv(r'Data\\information_train.csv', sep='\\t').rename(to_rename, axis=1)\n",
    "info_test = pd.read_csv(r'Data\\information_test.csv', sep='\\t').rename(to_rename, axis=1)\n",
    "info_all = pd.concat([info_train, info_test], axis=0)\n",
    "train = pd.read_csv(r'Data\\train.csv').rename(to_rename, axis=1)\n",
    "test = pd.read_csv(r'Data\\test.csv').rename(to_rename, axis=1)\n",
    "sample_sub = pd.read_csv(r'Data\\sample_submission_eSUXEfp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a function to create more distinctive print output\n",
    "def neat_print_sperator(name):\n",
    "    '''A function to create sperations between displays and prints'''\n",
    "    spacing_len = 95 - len(name)\n",
    "    print('{} {} {}'.format('_'*math.floor((spacing_len/2)), name, '_'*math.ceil(spacing_len/2)))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Data exploration\n",
    "\n",
    "[Back to table of contents](#123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________________________ train _____________________________________________\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm_id</th>\n",
       "      <th>ref_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17074820</td>\n",
       "      <td>['15153999', '15213210', '7668302']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15153999</td>\n",
       "      <td>['12721363', '9096352', '10788337', '9114021',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15213210</td>\n",
       "      <td>['11466240', '12184798']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7668302</td>\n",
       "      <td>['1539589']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12721363</td>\n",
       "      <td>['9465087', '11842208', '11309498', '9465125',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pm_id                                           ref_list\n",
       "0  17074820                ['15153999', '15213210', '7668302']\n",
       "1  15153999  ['12721363', '9096352', '10788337', '9114021',...\n",
       "2  15213210                           ['11466240', '12184798']\n",
       "3   7668302                                        ['1539589']\n",
       "4  12721363  ['9465087', '11842208', '11309498', '9465125',..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3,522; 2)\n",
      "\n",
      "__________________________________________ info_train ___________________________________________\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_str</th>\n",
       "      <th>title_str</th>\n",
       "      <th>authors_str</th>\n",
       "      <th>pm_id</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>set_num</th>\n",
       "      <th>text_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Among bioethicists and members of the public, ...</td>\n",
       "      <td>The routinisation of genomics and genetics: im...</td>\n",
       "      <td>M W Foster, C D M Royal, R R Sharp</td>\n",
       "      <td>17074820</td>\n",
       "      <td>2006-11-01</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Genomics resources that use samples from ident...</td>\n",
       "      <td>Integrating ethics and science in the Internat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15153999</td>\n",
       "      <td>2008-02-25</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alleviating health disparities in the United S...</td>\n",
       "      <td>Genetic Research and Health Disparities</td>\n",
       "      <td>Pamela Sankar, Mildred K. Cho, Celeste M. Cond...</td>\n",
       "      <td>15213210</td>\n",
       "      <td>2008-02-20</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Protecting the confidentiality of genetic rese...</td>\n",
       "      <td>Certificates of confidentiality: a valuable to...</td>\n",
       "      <td>C L Earley, L C Strong</td>\n",
       "      <td>7668302</td>\n",
       "      <td>1995-09-01</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Whereas the human linkage map appears on limit...</td>\n",
       "      <td>Linkage disequilibrium in human populations</td>\n",
       "      <td>Christine Lonjou, Weihua Zhang, Andrew Collins...</td>\n",
       "      <td>12721363</td>\n",
       "      <td>2003-05-13</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        abstract_str  \\\n",
       "0  Among bioethicists and members of the public, ...   \n",
       "1  Genomics resources that use samples from ident...   \n",
       "2  Alleviating health disparities in the United S...   \n",
       "3  Protecting the confidentiality of genetic rese...   \n",
       "4  Whereas the human linkage map appears on limit...   \n",
       "\n",
       "                                           title_str  \\\n",
       "0  The routinisation of genomics and genetics: im...   \n",
       "1  Integrating ethics and science in the Internat...   \n",
       "2            Genetic Research and Health Disparities   \n",
       "3  Certificates of confidentiality: a valuable to...   \n",
       "4        Linkage disequilibrium in human populations   \n",
       "\n",
       "                                         authors_str     pm_id    pub_date  \\\n",
       "0                 M W Foster, C D M Royal, R R Sharp  17074820  2006-11-01   \n",
       "1                                                NaN  15153999  2008-02-25   \n",
       "2  Pamela Sankar, Mildred K. Cho, Celeste M. Cond...  15213210  2008-02-20   \n",
       "3                             C L Earley, L C Strong   7668302  1995-09-01   \n",
       "4  Christine Lonjou, Weihua Zhang, Andrew Collins...  12721363  2003-05-13   \n",
       "\n",
       "   set_num text_str  \n",
       "0       13      NaN  \n",
       "1       13      NaN  \n",
       "2       13      NaN  \n",
       "3       13      NaN  \n",
       "4       13      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3,522; 7)\n",
      "\n",
      "_____________________________________________ test ______________________________________________\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14058267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4550818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14222809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4164675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6211173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pm_id\n",
       "0  14058267\n",
       "1   4550818\n",
       "2  14222809\n",
       "3   4164675\n",
       "4   6211173"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2,034; 1)\n",
      "\n",
      "___________________________________________ info_test ___________________________________________\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_str</th>\n",
       "      <th>title_str</th>\n",
       "      <th>authors_str</th>\n",
       "      <th>pm_id</th>\n",
       "      <th>pub_date</th>\n",
       "      <th>set_num</th>\n",
       "      <th>text_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cell lines selected in multiple steps for incr...</td>\n",
       "      <td>The gene for a novel protein, a member of the ...</td>\n",
       "      <td>M M Chaudhuri, P N Tonin, W H Lewis, P R Srini...</td>\n",
       "      <td>1311171</td>\n",
       "      <td>1992-02-01</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prolyl 4-hydroxylase (EC 1.14.11.2) is an esse...</td>\n",
       "      <td>Inhibition of prolyl 4-hydroxylase by hydroxya...</td>\n",
       "      <td>C J Cunliffe, T J Franklin</td>\n",
       "      <td>3028370</td>\n",
       "      <td>1986-10-15</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From the structure-activity relationships of k...</td>\n",
       "      <td>Time-dependent inactivation of chick-embryo pr...</td>\n",
       "      <td>V Gunzler, H M Hanauske-Abel, R Myllyla, J Moh...</td>\n",
       "      <td>3036081</td>\n",
       "      <td>1987-02-15</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The anthracyclines doxorubicin and daunorubici...</td>\n",
       "      <td>Syncatalytic inactivation of prolyl 4-hydroxyl...</td>\n",
       "      <td>V Gunzler, H M Hanauske-Abel, R Myllyla, D D K...</td>\n",
       "      <td>2840891</td>\n",
       "      <td>1988-04-15</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The levels of lysine hydroxylase protein and t...</td>\n",
       "      <td>Minoxidil specifically decreases the expressio...</td>\n",
       "      <td>T Hautala, J Heikkinen, K I Kivirikko, R Myllyla</td>\n",
       "      <td>1314568</td>\n",
       "      <td>1992-04-01</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        abstract_str  \\\n",
       "0  Cell lines selected in multiple steps for incr...   \n",
       "1  Prolyl 4-hydroxylase (EC 1.14.11.2) is an esse...   \n",
       "2  From the structure-activity relationships of k...   \n",
       "3  The anthracyclines doxorubicin and daunorubici...   \n",
       "4  The levels of lysine hydroxylase protein and t...   \n",
       "\n",
       "                                           title_str  \\\n",
       "0  The gene for a novel protein, a member of the ...   \n",
       "1  Inhibition of prolyl 4-hydroxylase by hydroxya...   \n",
       "2  Time-dependent inactivation of chick-embryo pr...   \n",
       "3  Syncatalytic inactivation of prolyl 4-hydroxyl...   \n",
       "4  Minoxidil specifically decreases the expressio...   \n",
       "\n",
       "                                         authors_str    pm_id    pub_date  \\\n",
       "0  M M Chaudhuri, P N Tonin, W H Lewis, P R Srini...  1311171  1992-02-01   \n",
       "1                         C J Cunliffe, T J Franklin  3028370  1986-10-15   \n",
       "2  V Gunzler, H M Hanauske-Abel, R Myllyla, J Moh...  3036081  1987-02-15   \n",
       "3  V Gunzler, H M Hanauske-Abel, R Myllyla, D D K...  2840891  1988-04-15   \n",
       "4   T Hautala, J Heikkinen, K I Kivirikko, R Myllyla  1314568  1992-04-01   \n",
       "\n",
       "   set_num text_str  \n",
       "0       17      NaN  \n",
       "1       17      NaN  \n",
       "2       17      NaN  \n",
       "3       17      NaN  \n",
       "4       17      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2,034; 7)\n",
      "\n",
      "__________________________________________ sample_sub ___________________________________________\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>ref_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14058267</td>\n",
       "      <td>['13367334','13367334']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4550818</td>\n",
       "      <td>['13367334']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14222809</td>\n",
       "      <td>['13367334']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4164675</td>\n",
       "      <td>['13367334']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6211173</td>\n",
       "      <td>['13367334']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pmid                 ref_list\n",
       "0  14058267  ['13367334','13367334']\n",
       "1   4550818             ['13367334']\n",
       "2  14222809             ['13367334']\n",
       "3   4164675             ['13367334']\n",
       "4   6211173             ['13367334']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2,034; 2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display different datasets and print their shapes\n",
    "dataset_dict = OrderedDict((name, eval(name)) for name in ['train', 'info_train', 'test', 'info_test', 'sample_sub'])\n",
    "\n",
    "for name, dataset in dataset_dict.items():\n",
    "    neat_print_sperator(name)\n",
    "    display(dataset.head())\n",
    "    get_seperator = lambda x: ';' if x[0] > 999 or x[1] > 999 else ','\n",
    "    print('shape: ({:,}{} {:,})\\n'.format(dataset.shape[0], get_seperator(dataset.shape), dataset.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________ abstract_str __________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Among bioethicists and members of the public, genetics is often regarded as unique in its ethical challenges. As medical researchers and clinicians increasingly combine genetic information with a range of non‐genetic information in the study and clinical management of patients with common diseases, the unique ethical challenges attributed to genetics must be re‐examined. A process of genetic routinisation that will have implications for research and clinical ethics, as well as for public conceptions of genetic information, is constituted by the emergence of new forms of genetic medicine, in which genetic information is interpreted in a multifactorial frame of reference. Although the integration of genetics in medical research and treatment may be a helpful corrective to the mistaken assumptions of genetic essentialism or determinism, the routinisation of genetics may have unintended consequences for the protection of genetic information, perceptions of non‐genetic information and the loss of genetic research as a laboratory for exploring issues in research and clinical ethics. Consequently, new ethical challenges are presented by the increasing routinisation of genetic information in both biomedical and public spheres.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________________ title_str ___________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The routinisation of genomics and genetics: implications for ethical practices'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________ authors_str __________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'M W Foster, C D M Royal, R R Sharp'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________________________ pm_id _____________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17074820"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________________ pub_date ____________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2006-11-01'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________ set_num ____________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________________ text_str ____________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Observe some data\n",
    "for name in info_train.columns:\n",
    "    neat_print_sperator(name)\n",
    "    display(info_train.loc[0, name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Data wrangling\n",
    "\n",
    "[Back to table of contents](#123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm_id</th>\n",
       "      <th>ref_id</th>\n",
       "      <th>is_referenced_flg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17074820</td>\n",
       "      <td>15213210</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17074820</td>\n",
       "      <td>7668302</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17074820</td>\n",
       "      <td>12721363</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17074820</td>\n",
       "      <td>9096352</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2274862</th>\n",
       "      <td>4335249</td>\n",
       "      <td>5775847</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2274863</th>\n",
       "      <td>4335249</td>\n",
       "      <td>13514006</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pm_id    ref_id  is_referenced_flg\n",
       "1        17074820  15213210                1.0\n",
       "2        17074820   7668302                1.0\n",
       "3        17074820  12721363                0.0\n",
       "4        17074820   9096352                0.0\n",
       "2274862   4335249   5775847                NaN\n",
       "2274863   4335249  13514006                NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get all possible pm_id combinations per set\n",
    "all_pm_id_combs = []\n",
    "for set_n in info_all.set_num.unique():\n",
    "    t = list(info_all.loc[info_all.set_num == set_n, 'pm_id'])\n",
    "    all_pm_id_combs = all_pm_id_combs + ['{}-{}'.format(x,y) for x in t for y in t if x != y]\n",
    "\n",
    "# Get all pm_id combinations that are referenced\n",
    "flagged_pm_id_combs = []\n",
    "for i, row in train.iterrows():\n",
    "    pm_id = row['pm_id']\n",
    "    ref_list = ast.literal_eval(row['ref_list'])\n",
    "    flagged_pm_id_combs = flagged_pm_id_combs + ['{}-{}'.format(pm_id, ref) for ref in ref_list]\n",
    "    \n",
    "# Get all pm_id in unlabeld data\n",
    "unlabeled_pm_id_combs = []\n",
    "for set_n in info_test.set_num.unique():\n",
    "    t = list(info_test.loc[info_test.set_num == set_n, 'pm_id'])\n",
    "    unlabeled_pm_id_combs = unlabeled_pm_id_combs + ['{}-{}'.format(x,y) for x in t for y in t if x != y]\n",
    "\n",
    "# Use all pm_id combinations to build a labelled dataframe\n",
    "data = pd.DataFrame(all_pm_id_combs).rename(columns={0:'pm_ref_id'})\n",
    "data['pm_id'] = data['pm_ref_id'].apply(lambda x: x.split('-')[0]).astype(int)\n",
    "data['ref_id'] = data['pm_ref_id'].apply(lambda x: x.split('-')[1]).astype(int)\n",
    "data['is_referenced_flg'] = False\n",
    "data.loc[data.pm_ref_id.isin(flagged_pm_id_combs), 'is_referenced_flg'] = True\n",
    "data.loc[data.pm_ref_id.isin(unlabeled_pm_id_combs), 'is_referenced_flg'] = np.nan\n",
    "data = data.drop(columns='pm_ref_id')\n",
    "\n",
    "# Set list with ids for later\n",
    "ids = ['pm_id', 'ref_id']\n",
    "\n",
    "# Observe data\n",
    "display(data.loc[[1,2,3,4,2274862,2274863], :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm_id</th>\n",
       "      <th>ref_id</th>\n",
       "      <th>is_referenced_flg</th>\n",
       "      <th>pm_abstract_str</th>\n",
       "      <th>ref_abstract_str</th>\n",
       "      <th>pm_title_str</th>\n",
       "      <th>ref_title_str</th>\n",
       "      <th>pm_authors_str</th>\n",
       "      <th>ref_authors_str</th>\n",
       "      <th>pm_pub_date</th>\n",
       "      <th>ref_pub_date</th>\n",
       "      <th>pm_text_str</th>\n",
       "      <th>ref_text_str</th>\n",
       "      <th>set_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17074820</td>\n",
       "      <td>15213210</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Among bioethicists and members of the public, ...</td>\n",
       "      <td>Alleviating health disparities in the United S...</td>\n",
       "      <td>The routinisation of genomics and genetics: im...</td>\n",
       "      <td>Genetic Research and Health Disparities</td>\n",
       "      <td>M W Foster, C D M Royal, R R Sharp</td>\n",
       "      <td>Pamela Sankar, Mildred K. Cho, Celeste M. Cond...</td>\n",
       "      <td>2006-11-01</td>\n",
       "      <td>2008-02-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17074820</td>\n",
       "      <td>7668302</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Among bioethicists and members of the public, ...</td>\n",
       "      <td>Protecting the confidentiality of genetic rese...</td>\n",
       "      <td>The routinisation of genomics and genetics: im...</td>\n",
       "      <td>Certificates of confidentiality: a valuable to...</td>\n",
       "      <td>M W Foster, C D M Royal, R R Sharp</td>\n",
       "      <td>C L Earley, L C Strong</td>\n",
       "      <td>2006-11-01</td>\n",
       "      <td>1995-09-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17074820</td>\n",
       "      <td>12721363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Among bioethicists and members of the public, ...</td>\n",
       "      <td>Whereas the human linkage map appears on limit...</td>\n",
       "      <td>The routinisation of genomics and genetics: im...</td>\n",
       "      <td>Linkage disequilibrium in human populations</td>\n",
       "      <td>M W Foster, C D M Royal, R R Sharp</td>\n",
       "      <td>Christine Lonjou, Weihua Zhang, Andrew Collins...</td>\n",
       "      <td>2006-11-01</td>\n",
       "      <td>2003-05-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17074820</td>\n",
       "      <td>9096352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Among bioethicists and members of the public, ...</td>\n",
       "      <td>We have examined differences in diversity at 6...</td>\n",
       "      <td>The routinisation of genomics and genetics: im...</td>\n",
       "      <td>Microsatellite diversity and the demographic h...</td>\n",
       "      <td>M W Foster, C D M Royal, R R Sharp</td>\n",
       "      <td>Lynn B. Jorde, Alan R. Rogers, Michael Bamshad...</td>\n",
       "      <td>2006-11-01</td>\n",
       "      <td>1997-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2274862</th>\n",
       "      <td>4335249</td>\n",
       "      <td>5775847</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Membrane-envelope fragments have been isolated...</td>\n",
       "      <td>Mitochondria were prepared from the spadices o...</td>\n",
       "      <td>RESPIRATION AND PROTEIN SYNTHESIS IN ESCHERICH...</td>\n",
       "      <td>The Respiratory Chain of Plant Mitochondria. I...</td>\n",
       "      <td>R. Scharff, R. W. Hendler, N. Nanninga, A. H. ...</td>\n",
       "      <td>Bayard T. Storey, James T. Bahr</td>\n",
       "      <td>1972-04-01</td>\n",
       "      <td>1969-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2274863</th>\n",
       "      <td>4335249</td>\n",
       "      <td>13514006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Membrane-envelope fragments have been isolated...</td>\n",
       "      <td>Respiration of a normal strain of Candida albi...</td>\n",
       "      <td>RESPIRATION AND PROTEIN SYNTHESIS IN ESCHERICH...</td>\n",
       "      <td>RESPIRATORY METABOLISM OF NORMAL AND DIVISIONL...</td>\n",
       "      <td>R. Scharff, R. W. Hendler, N. Nanninga, A. H. ...</td>\n",
       "      <td>John M. Ward, Walter J. Nickerson</td>\n",
       "      <td>1972-04-01</td>\n",
       "      <td>1958-03-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pm_id    ref_id  is_referenced_flg  \\\n",
       "1        17074820  15213210                1.0   \n",
       "2        17074820   7668302                1.0   \n",
       "3        17074820  12721363                0.0   \n",
       "4        17074820   9096352                0.0   \n",
       "2274862   4335249   5775847                NaN   \n",
       "2274863   4335249  13514006                NaN   \n",
       "\n",
       "                                           pm_abstract_str  \\\n",
       "1        Among bioethicists and members of the public, ...   \n",
       "2        Among bioethicists and members of the public, ...   \n",
       "3        Among bioethicists and members of the public, ...   \n",
       "4        Among bioethicists and members of the public, ...   \n",
       "2274862  Membrane-envelope fragments have been isolated...   \n",
       "2274863  Membrane-envelope fragments have been isolated...   \n",
       "\n",
       "                                          ref_abstract_str  \\\n",
       "1        Alleviating health disparities in the United S...   \n",
       "2        Protecting the confidentiality of genetic rese...   \n",
       "3        Whereas the human linkage map appears on limit...   \n",
       "4        We have examined differences in diversity at 6...   \n",
       "2274862  Mitochondria were prepared from the spadices o...   \n",
       "2274863  Respiration of a normal strain of Candida albi...   \n",
       "\n",
       "                                              pm_title_str  \\\n",
       "1        The routinisation of genomics and genetics: im...   \n",
       "2        The routinisation of genomics and genetics: im...   \n",
       "3        The routinisation of genomics and genetics: im...   \n",
       "4        The routinisation of genomics and genetics: im...   \n",
       "2274862  RESPIRATION AND PROTEIN SYNTHESIS IN ESCHERICH...   \n",
       "2274863  RESPIRATION AND PROTEIN SYNTHESIS IN ESCHERICH...   \n",
       "\n",
       "                                             ref_title_str  \\\n",
       "1                  Genetic Research and Health Disparities   \n",
       "2        Certificates of confidentiality: a valuable to...   \n",
       "3              Linkage disequilibrium in human populations   \n",
       "4        Microsatellite diversity and the demographic h...   \n",
       "2274862  The Respiratory Chain of Plant Mitochondria. I...   \n",
       "2274863  RESPIRATORY METABOLISM OF NORMAL AND DIVISIONL...   \n",
       "\n",
       "                                            pm_authors_str  \\\n",
       "1                       M W Foster, C D M Royal, R R Sharp   \n",
       "2                       M W Foster, C D M Royal, R R Sharp   \n",
       "3                       M W Foster, C D M Royal, R R Sharp   \n",
       "4                       M W Foster, C D M Royal, R R Sharp   \n",
       "2274862  R. Scharff, R. W. Hendler, N. Nanninga, A. H. ...   \n",
       "2274863  R. Scharff, R. W. Hendler, N. Nanninga, A. H. ...   \n",
       "\n",
       "                                           ref_authors_str pm_pub_date  \\\n",
       "1        Pamela Sankar, Mildred K. Cho, Celeste M. Cond...  2006-11-01   \n",
       "2                                   C L Earley, L C Strong  2006-11-01   \n",
       "3        Christine Lonjou, Weihua Zhang, Andrew Collins...  2006-11-01   \n",
       "4        Lynn B. Jorde, Alan R. Rogers, Michael Bamshad...  2006-11-01   \n",
       "2274862                    Bayard T. Storey, James T. Bahr  1972-04-01   \n",
       "2274863                  John M. Ward, Walter J. Nickerson  1972-04-01   \n",
       "\n",
       "        ref_pub_date pm_text_str ref_text_str  set_num  \n",
       "1         2008-02-20         NaN          NaN       13  \n",
       "2         1995-09-01         NaN          NaN       13  \n",
       "3         2003-05-13         NaN          NaN       13  \n",
       "4         1997-04-01         NaN          NaN       13  \n",
       "2274862   1969-01-01         NaN          NaN       19  \n",
       "2274863   1958-03-20         NaN          NaN       19  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Change the index of the info_train dataframe to make mapping easier, whilst not overwriting the original dataframe\n",
    "articles = info_all.copy()\n",
    "articles.index = articles['pm_id']\n",
    "articles = articles.drop(columns='pm_id')\n",
    "\n",
    "# Enrich dataframe with both info of pm- and ref-article by mapping the articles\n",
    "for col in [col for col in articles.columns if col != 'set_num']:\n",
    "    mapper = articles[col]\n",
    "    \n",
    "    if col == 'pub_date':\n",
    "        mapper = pd.to_datetime(mapper)\n",
    "    \n",
    "    data['pm_' + col] = data['pm_id'].map(mapper)\n",
    "    data['ref_' + col] = data['ref_id'].map(mapper)\n",
    "\n",
    "# Transmit set number aswell (is the same for both pm- and ref-article)\n",
    "data['set_num'] = data.pm_id.map(articles['set_num'])\n",
    "\n",
    "# Observe dataframe\n",
    "data.head()\n",
    "\n",
    "# Observe data\n",
    "display(data.loc[[1,2,3,4,2274862,2274863], :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Feature engineering\n",
    "\n",
    "[Back to table of contents](#123)\n",
    "<a id='31'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1) Basic feature extraction\n",
    "\n",
    "[Back to table of contents](#123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract time difference between publication date of pm- and ref-article\n",
    "data['diff_pub_date_day_cnt'] = (data['pm_pub_date'] - data['ref_pub_date']).astype('timedelta64[D]').astype(int)\n",
    "\n",
    "# Extract plucation years of pm- and ref-article\n",
    "data['pm_pub_year_num'] = data['pm_pub_date'].apply(lambda x: x.year)\n",
    "data['ref_pub_year_num'] = data['ref_pub_date'].apply(lambda x: x.year)\n",
    "\n",
    "# Count the authors of pm- and ref-article\n",
    "lmbda = lambda x: len(str(x).split(', ')) if not pd.isnull(x) else 0\n",
    "data['pm_author_cnt'] = data['pm_authors_str'].apply(lmbda)\n",
    "data['ref_author_cnt'] = data['ref_authors_str'].apply(lmbda)\n",
    "\n",
    "# Extract missing value flags for authors of pm- and ref-article\n",
    "data['pm_author_mv_flg'] = data['pm_authors_str'].isnull()\n",
    "data['ref_author_mv_flg'] = data['ref_authors_str'].isnull()\n",
    "\n",
    "# Extract missing value flags for text of pm- and ref-article\n",
    "data['pm_full_text_mv_flg'] = data['pm_text_str'].isnull()\n",
    "data['ref_full_text_mv_flg'] = data['ref_text_str'].isnull()\n",
    "\n",
    "# Count charachters used in the title of pm- and ref-article\n",
    "data['pm_title_char_cnt'] = data['pm_title_str'].apply(lambda x: len(x))\n",
    "data['ref_title_char_cnt'] = data['ref_title_str'].apply(lambda x: len(x))\n",
    "\n",
    "# Count words used in the title of pm- and ref-article\n",
    "data['pm_title_word_cnt'] = data['pm_title_str'].apply(lambda x: len(x.split(' ')))\n",
    "data['ref_title_word_cnt'] = data['ref_title_str'].apply(lambda x: len(x.split(' ')))\n",
    "\n",
    "# Count charachters used in the abstract of pm- and ref-article\n",
    "data['pm_abstract_char_cnt'] = data['pm_abstract_str'].apply(lambda x: len(x))\n",
    "data['ref_abstract_char_cnt'] = data['ref_abstract_str'].apply(lambda x: len(x))\n",
    "\n",
    "# Count words used in the abstract of pm- and ref-article\n",
    "data['pm_abstract_word_cnt'] = data['pm_abstract_str'].apply(lambda x: len(x.split(' ')))\n",
    "data['ref_abstract_word_cnt'] = data['ref_abstract_str'].apply(lambda x: len(x.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm_id</th>\n",
       "      <th>ref_id</th>\n",
       "      <th>is_referenced_flg</th>\n",
       "      <th>pm_pub_date</th>\n",
       "      <th>ref_pub_date</th>\n",
       "      <th>set_num</th>\n",
       "      <th>diff_pub_date_day_cnt</th>\n",
       "      <th>pm_pub_year_num</th>\n",
       "      <th>ref_pub_year_num</th>\n",
       "      <th>pm_author_cnt</th>\n",
       "      <th>...</th>\n",
       "      <th>pm_full_text_mv_flg</th>\n",
       "      <th>ref_full_text_mv_flg</th>\n",
       "      <th>pm_title_char_cnt</th>\n",
       "      <th>ref_title_char_cnt</th>\n",
       "      <th>pm_title_word_cnt</th>\n",
       "      <th>ref_title_word_cnt</th>\n",
       "      <th>pm_abstract_char_cnt</th>\n",
       "      <th>ref_abstract_char_cnt</th>\n",
       "      <th>pm_abstract_word_cnt</th>\n",
       "      <th>ref_abstract_word_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17074820</td>\n",
       "      <td>15153999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2006-11-01</td>\n",
       "      <td>2008-02-25</td>\n",
       "      <td>13</td>\n",
       "      <td>-481</td>\n",
       "      <td>2006</td>\n",
       "      <td>2008</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>78</td>\n",
       "      <td>66</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>1238</td>\n",
       "      <td>907</td>\n",
       "      <td>177</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17074820</td>\n",
       "      <td>15213210</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2006-11-01</td>\n",
       "      <td>2008-02-20</td>\n",
       "      <td>13</td>\n",
       "      <td>-476</td>\n",
       "      <td>2006</td>\n",
       "      <td>2008</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>78</td>\n",
       "      <td>39</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1238</td>\n",
       "      <td>998</td>\n",
       "      <td>177</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17074820</td>\n",
       "      <td>7668302</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2006-11-01</td>\n",
       "      <td>1995-09-01</td>\n",
       "      <td>13</td>\n",
       "      <td>4079</td>\n",
       "      <td>2006</td>\n",
       "      <td>1995</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>78</td>\n",
       "      <td>77</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1238</td>\n",
       "      <td>880</td>\n",
       "      <td>177</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17074820</td>\n",
       "      <td>12721363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2006-11-01</td>\n",
       "      <td>2003-05-13</td>\n",
       "      <td>13</td>\n",
       "      <td>1268</td>\n",
       "      <td>2006</td>\n",
       "      <td>2003</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>78</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1238</td>\n",
       "      <td>1703</td>\n",
       "      <td>177</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17074820</td>\n",
       "      <td>9096352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2006-11-01</td>\n",
       "      <td>1997-04-01</td>\n",
       "      <td>13</td>\n",
       "      <td>3501</td>\n",
       "      <td>2006</td>\n",
       "      <td>1997</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>78</td>\n",
       "      <td>69</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1238</td>\n",
       "      <td>1219</td>\n",
       "      <td>177</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pm_id    ref_id  is_referenced_flg pm_pub_date ref_pub_date  set_num  \\\n",
       "0  17074820  15153999                1.0  2006-11-01   2008-02-25       13   \n",
       "1  17074820  15213210                1.0  2006-11-01   2008-02-20       13   \n",
       "2  17074820   7668302                1.0  2006-11-01   1995-09-01       13   \n",
       "3  17074820  12721363                0.0  2006-11-01   2003-05-13       13   \n",
       "4  17074820   9096352                0.0  2006-11-01   1997-04-01       13   \n",
       "\n",
       "   diff_pub_date_day_cnt  pm_pub_year_num  ref_pub_year_num  pm_author_cnt  \\\n",
       "0                   -481             2006              2008              3   \n",
       "1                   -476             2006              2008              3   \n",
       "2                   4079             2006              1995              3   \n",
       "3                   1268             2006              2003              3   \n",
       "4                   3501             2006              1997              3   \n",
       "\n",
       "           ...            pm_full_text_mv_flg  ref_full_text_mv_flg  \\\n",
       "0          ...                           True                  True   \n",
       "1          ...                           True                  True   \n",
       "2          ...                           True                  True   \n",
       "3          ...                           True                  True   \n",
       "4          ...                           True                  True   \n",
       "\n",
       "   pm_title_char_cnt  ref_title_char_cnt  pm_title_word_cnt  \\\n",
       "0                 78                  66                 10   \n",
       "1                 78                  39                 10   \n",
       "2                 78                  77                 10   \n",
       "3                 78                  43                 10   \n",
       "4                 78                  69                 10   \n",
       "\n",
       "   ref_title_word_cnt  pm_abstract_char_cnt  ref_abstract_char_cnt  \\\n",
       "0                   9                  1238                    907   \n",
       "1                   5                  1238                    998   \n",
       "2                  10                  1238                    880   \n",
       "3                   5                  1238                   1703   \n",
       "4                   7                  1238                   1219   \n",
       "\n",
       "   pm_abstract_word_cnt  ref_abstract_word_cnt  \n",
       "0                   177                    131  \n",
       "1                   177                    143  \n",
       "2                   177                    129  \n",
       "3                   177                    254  \n",
       "4                   177                    171  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observe created features\n",
    "data[[col for col in data.columns if not col.endswith('str')]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='32'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2) Extracting and engineering features from authors\n",
    "\n",
    "[Back to table of contents](#123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract common authors in pm- and ref-article\n",
    "common_authors_list = []\n",
    "for i, row in data.iterrows():\n",
    "    if pd.isnull(row['pm_authors_str']) or pd.isnull(row['ref_authors_str']):\n",
    "        common_authors_list.append(np.nan)\n",
    "    else:\n",
    "        pm_author_list = row['pm_authors_str'].split(', ')\n",
    "        ref_author_list = row['ref_authors_str'].split(', ')\n",
    "        common_authors_list.append(list(set(pm_author_list).intersection(ref_author_list)))\n",
    "        \n",
    "data['common_authors_list'] = common_authors_list\n",
    "\n",
    "# Count common authors in pm- and ref-article\n",
    "lmbda = lambda x: len(x) if type(x) != type(np.nan) else 0\n",
    "data['common_authors_cnt'] = data['common_authors_list'].apply(lmbda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean all author strings\n",
    "def authors_to_list(x):\n",
    "    x = re.sub('\\r|\\n', '', x)\n",
    "    x = x.split(', ')\n",
    "    return(x)\n",
    "\n",
    "info_all['authors_list'] = info_all.authors_str.fillna('').astype(str).apply(authors_to_list)\n",
    "data['pm_authors_list'] = data['pm_authors_str'].fillna('').astype(str).apply(authors_to_list)\n",
    "data['ref_authors_list'] = data['ref_authors_str'].fillna('').astype(str).apply(authors_to_list)\n",
    "\n",
    "# Creaet dict with authors and their publications\n",
    "author_dict = {}\n",
    "for i, row in info_all.iterrows():\n",
    "    for author in row['authors_list']:\n",
    "        if author in author_dict.keys():\n",
    "            author_dict[author].append(row['set_num'])\n",
    "        else:\n",
    "            author_dict[author] = [row['set_num']]\n",
    "            \n",
    "# Set the publications of the missing value author to an empty string            \n",
    "author_dict[''] = ''\n",
    "\n",
    "# Extract min, max and mean amount of publications for the authors of both pm- and ref-article\n",
    "results = {}\n",
    "for i, row in data.iterrows():   \n",
    "    pm_author_pub_counts = []\n",
    "    for author in row['pm_authors_list']:\n",
    "        pm_author_pub_counts.append(len(author_dict[author]))\n",
    "    \n",
    "    ref_author_pub_counts = []\n",
    "    for author in row['ref_authors_list']:\n",
    "        ref_author_pub_counts.append(len(author_dict[author]))\n",
    "    \n",
    "    # max, mean, min? sum       \n",
    "    results[i] = [max(pm_author_pub_counts), np.mean(pm_author_pub_counts),\n",
    "                  min(pm_author_pub_counts), sum(pm_author_pub_counts),\n",
    "                  max(ref_author_pub_counts), np.mean(ref_author_pub_counts),\n",
    "                  min(ref_author_pub_counts), sum(ref_author_pub_counts)]\n",
    "                  \n",
    "df_r = pd.DataFrame(results, index=['pm_authors_max_pub_cnt', 'pm_authors_mean_pub_cnt',\n",
    "                                    'pm_authors_min_pub_cnt', 'pm_authors_total_pub_cnt',\n",
    "                                    'ref_authors_max_pub_cnt', 'ref_authors_mean_pub_cnt',\n",
    "                                    'ref_authors_min_pub_cnt', 'ref_authors_total_pub_cnt']).transpose()\n",
    "\n",
    "data = pd.concat([data, df_r], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm_id</th>\n",
       "      <th>ref_id</th>\n",
       "      <th>is_referenced_flg</th>\n",
       "      <th>set_num</th>\n",
       "      <th>diff_pub_date_day_cnt</th>\n",
       "      <th>pm_pub_year_num</th>\n",
       "      <th>ref_pub_year_num</th>\n",
       "      <th>pm_author_cnt</th>\n",
       "      <th>ref_author_cnt</th>\n",
       "      <th>pm_author_mv_flg</th>\n",
       "      <th>...</th>\n",
       "      <th>ref_abstract_word_cnt</th>\n",
       "      <th>common_authors_cnt</th>\n",
       "      <th>pm_authors_max_pub_cnt</th>\n",
       "      <th>pm_authors_mean_pub_cnt</th>\n",
       "      <th>pm_authors_min_pub_cnt</th>\n",
       "      <th>pm_authors_total_pub_cnt</th>\n",
       "      <th>ref_authors_max_pub_cnt</th>\n",
       "      <th>ref_authors_mean_pub_cnt</th>\n",
       "      <th>ref_authors_min_pub_cnt</th>\n",
       "      <th>ref_authors_total_pub_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17074820</td>\n",
       "      <td>15153999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>-481</td>\n",
       "      <td>2006</td>\n",
       "      <td>2008</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17074820</td>\n",
       "      <td>15213210</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>-476</td>\n",
       "      <td>2006</td>\n",
       "      <td>2008</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17074820</td>\n",
       "      <td>7668302</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>4079</td>\n",
       "      <td>2006</td>\n",
       "      <td>1995</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17074820</td>\n",
       "      <td>12721363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>1268</td>\n",
       "      <td>2006</td>\n",
       "      <td>2003</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17074820</td>\n",
       "      <td>9096352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>3501</td>\n",
       "      <td>2006</td>\n",
       "      <td>1997</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pm_id    ref_id  is_referenced_flg  set_num  diff_pub_date_day_cnt  \\\n",
       "0  17074820  15153999                1.0       13                   -481   \n",
       "1  17074820  15213210                1.0       13                   -476   \n",
       "2  17074820   7668302                1.0       13                   4079   \n",
       "3  17074820  12721363                0.0       13                   1268   \n",
       "4  17074820   9096352                0.0       13                   3501   \n",
       "\n",
       "   pm_pub_year_num  ref_pub_year_num  pm_author_cnt  ref_author_cnt  \\\n",
       "0             2006              2008              3               0   \n",
       "1             2006              2008              3               8   \n",
       "2             2006              1995              3               2   \n",
       "3             2006              2003              3               7   \n",
       "4             2006              1997              3               8   \n",
       "\n",
       "   pm_author_mv_flg            ...              ref_abstract_word_cnt  \\\n",
       "0             False            ...                                131   \n",
       "1             False            ...                                143   \n",
       "2             False            ...                                129   \n",
       "3             False            ...                                254   \n",
       "4             False            ...                                171   \n",
       "\n",
       "   common_authors_cnt  pm_authors_max_pub_cnt  pm_authors_mean_pub_cnt  \\\n",
       "0                   0                     2.0                 1.666667   \n",
       "1                   0                     2.0                 1.666667   \n",
       "2                   0                     2.0                 1.666667   \n",
       "3                   0                     2.0                 1.666667   \n",
       "4                   0                     2.0                 1.666667   \n",
       "\n",
       "   pm_authors_min_pub_cnt  pm_authors_total_pub_cnt  ref_authors_max_pub_cnt  \\\n",
       "0                     1.0                       5.0                      0.0   \n",
       "1                     1.0                       5.0                      1.0   \n",
       "2                     1.0                       5.0                      1.0   \n",
       "3                     1.0                       5.0                      4.0   \n",
       "4                     1.0                       5.0                      5.0   \n",
       "\n",
       "   ref_authors_mean_pub_cnt  ref_authors_min_pub_cnt  \\\n",
       "0                  0.000000                      0.0   \n",
       "1                  1.000000                      1.0   \n",
       "2                  1.000000                      1.0   \n",
       "3                  2.285714                      1.0   \n",
       "4                  2.000000                      1.0   \n",
       "\n",
       "   ref_authors_total_pub_cnt  \n",
       "0                        0.0  \n",
       "1                        8.0  \n",
       "2                        2.0  \n",
       "3                       16.0  \n",
       "4                       16.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove text features\n",
    "to_drop = [col for col in data.columns if col.endswith('str') or col.endswith('list') or col.endswith('date') ]\n",
    "data = data.drop(columns=to_drop)\n",
    "\n",
    "# Observe current dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='33'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3) Extracting and engineering features from text fields\n",
    "\n",
    "[Back to table of contents](#123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** HELPER FUNCTIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiations from the natural language toolkit\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "word_punct_tokenizer = nltk.WordPunctTokenizer()\n",
    "\n",
    "port_stemmer = nltk.stem.PorterStemmer()\n",
    "word_net_lemmatizer = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some helper functions\n",
    "def get_pos(word):\n",
    "    wordnet_synsets = nltk.corpus.wordnet.synsets(word)\n",
    "    pos_counts = Counter()\n",
    "    pos_counts['n'] = len([ item for item in wordnet_synsets if item.pos()== 'n'])\n",
    "    pos_counts['v'] = len([ item for item in wordnet_synsets if item.pos()== 'v'])\n",
    "    pos_counts['a'] = len([ item for item in wordnet_synsets if item.pos()== 'a'])\n",
    "    pos_counts['r'] = len([ item for item in wordnet_synsets if item.pos()== 'r'])\n",
    "    most_common_pos_list = pos_counts.most_common(3)\n",
    "    return most_common_pos_list[0][0]\n",
    "\n",
    "def document_normalizer(doc, how='stemming'):\n",
    "    # Strip everything but white spaces and alpha numeric\n",
    "    doc = re.sub('([^\\s\\w]|_)+', '', doc)\n",
    "    \n",
    "    # Tokenize document, lowercase tokens and remove tokens that have length of 1\n",
    "    tokens = [token.lower() for token in word_punct_tokenizer.tokenize(doc) if len(token) > 1]\n",
    "    \n",
    "    # Filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    if how == 'stemming':\n",
    "        # Stem tokens \n",
    "        cleaned_tokes = [port_stemmer.stem(token) for token in filtered_tokens]\n",
    "    elif how == 'lemmatization':\n",
    "        # Lemmatize tokens\n",
    "        cleaned_tokes = [word_net_lemmatizer.lemmatize(token, get_pos(token)) for token in filtered_tokens]\n",
    "    else:\n",
    "        raise ValueError('Specify how to normalize')\n",
    "        \n",
    "    # Re-create document from cleaned tokens\n",
    "    doc = ' '.join(cleaned_tokes)\n",
    "    \n",
    "    return doc\n",
    "\n",
    "corpus_normalizer = np.vectorize(document_normalizer)\n",
    "\n",
    "def n3gram(norm_corpus, dataframe_ids, min_dif=1, max_df=0.5, ngram_range=(1,3)):\n",
    "    cv = CountVectorizer(min_df=min_dif, max_df=max_df, ngram_range=ngram_range)\n",
    "    \n",
    "    cv_matrix = cv.fit_transform(norm_corpus).toarray()\n",
    "    cv_df = pd.DataFrame(cv_matrix, columns=cv.get_feature_names(), index=dataframe_ids)\n",
    "    \n",
    "    cv_sim_matrix = cosine_similarity(cv_matrix)\n",
    "    cv_sim_df = pd.DataFrame(cv_sim_matrix, index=dataframe_ids, columns=dataframe_ids)\n",
    "    \n",
    "    return cv_sim_df, cv_df\n",
    "\n",
    "def tfidf(norm_corpus, dataframe_ids, min_dif=1, max_df=0.5, ngram_range=(1,1)):\n",
    "    tv = TfidfVectorizer(min_df=1, max_df=0.5, ngram_range=ngram_range, use_idf=True)\n",
    "    \n",
    "    tv_matrix = tv.fit_transform(norm_corpus).toarray()  \n",
    "    tv_df = pd.DataFrame(tv_matrix, columns=tv.get_feature_names(), index=dataframe_ids)\n",
    "    \n",
    "    tv_sim_matrix = cosine_similarity(tv_matrix)\n",
    "    tv_sim_df = pd.DataFrame(tv_sim_matrix, index=dataframe_ids, columns=dataframe_ids)\n",
    "    \n",
    "    return tv_sim_df, tv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** SHOW CASE HOW HELPER FUNCTIONS WORK **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm_id</th>\n",
       "      <th>ref_id</th>\n",
       "      <th>is_referenced_flg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17074820</td>\n",
       "      <td>15153999</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17074820</td>\n",
       "      <td>15213210</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17074820</td>\n",
       "      <td>12721363</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17074820</td>\n",
       "      <td>9096352</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pm_id    ref_id  is_referenced_flg\n",
       "0  17074820  15153999                1.0\n",
       "1  17074820  15213210                1.0\n",
       "3  17074820  12721363                0.0\n",
       "4  17074820   9096352                0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample some observations (of which some are referenced)\n",
    "sample = data.loc[[0,1,3,4], ['pm_id', 'ref_id', 'is_referenced_flg']]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample corpus\n",
    "sample_ids = list(sample['pm_id'].unique()) + list(sample['ref_id'])\n",
    "sample_corpus  = info_train.loc[train.pm_id.isin(sample_ids), 'title_str']\n",
    "sample_corpus.index = sample_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________________ original ____________________________________________\n",
      "\n",
      "17074820: The routinisation of genomics and genetics: implications for ethical practices\n",
      "\n",
      "15153999: Integrating ethics and science in the International HapMap Project\n",
      "\n",
      "15213210: Genetic Research and Health Disparities\n",
      "\n",
      "12721363: Linkage disequilibrium in human populations\n",
      "\n",
      "9096352 : Microsatellite diversity and the demographic history of modern humans\n",
      "\n",
      "____________________________________________ stemmed ____________________________________________\n",
      "\n",
      "17074820: routinis genom genet implic ethic practic\n",
      "\n",
      "15153999: integr ethic scienc intern hapmap project\n",
      "\n",
      "15213210: genet research health dispar\n",
      "\n",
      "12721363: linkag disequilibrium human popul\n",
      "\n",
      "9096352 : microsatellit divers demograph histori modern human\n",
      "\n",
      "__________________________________________ lemmatized ___________________________________________\n",
      "\n",
      "17074820: routinisation genomics genetics implication ethical practice\n",
      "\n",
      "15153999: integrate ethic science international hapmap project\n",
      "\n",
      "15213210: genetic research health disparity\n",
      "\n",
      "12721363: linkage disequilibrium human population\n",
      "\n",
      "9096352 : microsatellite diversity demographic history modern human\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show how lemmatizer and stemmer work\n",
    "space_evener = lambda x: ' '*(8-len(str(x)))\n",
    "\n",
    "neat_print_sperator('original')\n",
    "print()\n",
    "for i in range(0,5):\n",
    "    print('{}{}: {}'.format(sample_ids[i], space_evener(sample_ids[i]),sample_corpus.iloc[i]))\n",
    "    print()\n",
    "\n",
    "neat_print_sperator('stemmed')\n",
    "print()\n",
    "for i in range(0,5):\n",
    "    print('{}{}: {}'.format(sample_ids[i], space_evener(sample_ids[i]),\n",
    "                            corpus_normalizer(sample_corpus.iloc[i], how='stemming')))\n",
    "    print()\n",
    "\n",
    "neat_print_sperator('lemmatized')\n",
    "print()\n",
    "for i in range(0,5):\n",
    "    print('{}{}: {}'.format(sample_ids[i], space_evener(sample_ids[i]),\n",
    "                            corpus_normalizer(sample_corpus.iloc[i], how='lemmatization')))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________ Extracted stemmed 3gram features ________________________________\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demograph</th>\n",
       "      <th>demograph histori</th>\n",
       "      <th>demograph histori modern</th>\n",
       "      <th>disequilibrium</th>\n",
       "      <th>disequilibrium human</th>\n",
       "      <th>disequilibrium human popul</th>\n",
       "      <th>dispar</th>\n",
       "      <th>divers</th>\n",
       "      <th>divers demograph</th>\n",
       "      <th>divers demograph histori</th>\n",
       "      <th>...</th>\n",
       "      <th>project</th>\n",
       "      <th>research</th>\n",
       "      <th>research health</th>\n",
       "      <th>research health dispar</th>\n",
       "      <th>routinis</th>\n",
       "      <th>routinis genom</th>\n",
       "      <th>routinis genom genet</th>\n",
       "      <th>scienc</th>\n",
       "      <th>scienc intern</th>\n",
       "      <th>scienc intern hapmap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17074820</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15153999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15213210</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12721363</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9096352</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          demograph  demograph histori  demograph histori modern  \\\n",
       "17074820          0                  0                         0   \n",
       "15153999          0                  0                         0   \n",
       "15213210          0                  0                         0   \n",
       "12721363          0                  0                         0   \n",
       "9096352           1                  1                         1   \n",
       "\n",
       "          disequilibrium  disequilibrium human  disequilibrium human popul  \\\n",
       "17074820               0                     0                           0   \n",
       "15153999               0                     0                           0   \n",
       "15213210               0                     0                           0   \n",
       "12721363               1                     1                           1   \n",
       "9096352                0                     0                           0   \n",
       "\n",
       "          dispar  divers  divers demograph  divers demograph histori  \\\n",
       "17074820       0       0                 0                         0   \n",
       "15153999       0       0                 0                         0   \n",
       "15213210       1       0                 0                         0   \n",
       "12721363       0       0                 0                         0   \n",
       "9096352        0       1                 1                         1   \n",
       "\n",
       "                  ...           project  research  research health  \\\n",
       "17074820          ...                 0         0                0   \n",
       "15153999          ...                 1         0                0   \n",
       "15213210          ...                 0         1                1   \n",
       "12721363          ...                 0         0                0   \n",
       "9096352           ...                 0         0                0   \n",
       "\n",
       "          research health dispar  routinis  routinis genom  \\\n",
       "17074820                       0         1               1   \n",
       "15153999                       0         0               0   \n",
       "15213210                       1         0               0   \n",
       "12721363                       0         0               0   \n",
       "9096352                        0         0               0   \n",
       "\n",
       "          routinis genom genet  scienc  scienc intern  scienc intern hapmap  \n",
       "17074820                     1       0              0                     0  \n",
       "15153999                     0       1              1                     1  \n",
       "15213210                     0       0              0                     0  \n",
       "12721363                     0       0              0                     0  \n",
       "9096352                      0       0              0                     0  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "__________________________ Similarity matrix of stemmed 3gram features __________________________\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>17074820</th>\n",
       "      <th>15153999</th>\n",
       "      <th>15213210</th>\n",
       "      <th>12721363</th>\n",
       "      <th>9096352</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17074820</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15153999</th>\n",
       "      <td>0.067</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15213210</th>\n",
       "      <td>0.086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12721363</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9096352</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         17074820 15153999 15213210 12721363 9096352 \n",
       "17074820      1.0    0.067    0.086      0.0      0.0\n",
       "15153999    0.067      1.0      0.0      0.0      0.0\n",
       "15213210    0.086      0.0      1.0      0.0      0.0\n",
       "12721363      0.0      0.0      0.0      1.0    0.086\n",
       "9096352       0.0      0.0      0.0    0.086      1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show how 3gram works\n",
    "norm_corpus = corpus_normalizer(sample_corpus, how='stemming')\n",
    "similarity_df, features_df =  n3gram(norm_corpus, max_df=0.5, dataframe_ids=sample_corpus.index)\n",
    "\n",
    "neat_print_sperator('Extracted stemmed 3gram features')\n",
    "display(features_df)\n",
    "print()\n",
    "\n",
    "neat_print_sperator('Similarity matrix of stemmed 3gram features')\n",
    "display(similarity_df.applymap(lambda x: '{:0.2}'.format(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________ Extracted lemmatized tfidf features ______________________________\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demographic</th>\n",
       "      <th>disequilibrium</th>\n",
       "      <th>disparity</th>\n",
       "      <th>diversity</th>\n",
       "      <th>ethic</th>\n",
       "      <th>ethical</th>\n",
       "      <th>genetic</th>\n",
       "      <th>genetics</th>\n",
       "      <th>genomics</th>\n",
       "      <th>hapmap</th>\n",
       "      <th>...</th>\n",
       "      <th>international</th>\n",
       "      <th>linkage</th>\n",
       "      <th>microsatellite</th>\n",
       "      <th>modern</th>\n",
       "      <th>population</th>\n",
       "      <th>practice</th>\n",
       "      <th>project</th>\n",
       "      <th>research</th>\n",
       "      <th>routinisation</th>\n",
       "      <th>science</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17074820</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15153999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.41</td>\n",
       "      <td>...</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15213210</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12721363</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9096352</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         demographic disequilibrium disparity diversity ethic ethical genetic  \\\n",
       "17074820         0.0            0.0       0.0       0.0   0.0    0.41     0.0   \n",
       "15153999         0.0            0.0       0.0       0.0  0.41     0.0     0.0   \n",
       "15213210         0.0            0.0       0.5       0.0   0.0     0.0     0.5   \n",
       "12721363         0.0           0.52       0.0       0.0   0.0     0.0     0.0   \n",
       "9096352         0.42            0.0       0.0      0.42   0.0     0.0     0.0   \n",
       "\n",
       "         genetics genomics hapmap   ...   international linkage  \\\n",
       "17074820     0.41     0.41    0.0   ...             0.0     0.0   \n",
       "15153999      0.0      0.0   0.41   ...            0.41     0.0   \n",
       "15213210      0.0      0.0    0.0   ...             0.0     0.0   \n",
       "12721363      0.0      0.0    0.0   ...             0.0    0.52   \n",
       "9096352       0.0      0.0    0.0   ...             0.0     0.0   \n",
       "\n",
       "         microsatellite modern population practice project research  \\\n",
       "17074820            0.0    0.0        0.0     0.41     0.0      0.0   \n",
       "15153999            0.0    0.0        0.0      0.0    0.41      0.0   \n",
       "15213210            0.0    0.0        0.0      0.0     0.0      0.5   \n",
       "12721363            0.0    0.0       0.52      0.0     0.0      0.0   \n",
       "9096352            0.42   0.42        0.0      0.0     0.0      0.0   \n",
       "\n",
       "         routinisation science  \n",
       "17074820          0.41     0.0  \n",
       "15153999           0.0    0.41  \n",
       "15213210           0.0     0.0  \n",
       "12721363           0.0     0.0  \n",
       "9096352            0.0     0.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "________________________ Similarity matrix of lemmatized tfidf features _________________________\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>17074820</th>\n",
       "      <th>15153999</th>\n",
       "      <th>15213210</th>\n",
       "      <th>12721363</th>\n",
       "      <th>9096352</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17074820</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15153999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15213210</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12721363</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9096352</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         17074820 15153999 15213210 12721363 9096352 \n",
       "17074820      1.0      0.0      0.0      0.0      0.0\n",
       "15153999      0.0      1.0      0.0      0.0      0.0\n",
       "15213210      0.0      0.0      1.0      0.0      0.0\n",
       "12721363      0.0      0.0      0.0      1.0     0.14\n",
       "9096352       0.0      0.0      0.0     0.14      1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show how tfidf works\n",
    "norm_corpus = corpus_normalizer(sample_corpus, how='lemmatization')\n",
    "similarity_df, features_df =  tfidf(norm_corpus, max_df=0.5, dataframe_ids=sample_corpus.index)\n",
    "\n",
    "neat_print_sperator('Extracted lemmatized tfidf features')\n",
    "display(features_df.applymap(lambda x: '{:0.2}'.format(x)))\n",
    "print()\n",
    "\n",
    "neat_print_sperator('Similarity matrix of lemmatized tfidf features')\n",
    "display(similarity_df.applymap(lambda x: '{:0.2}'.format(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** ACTUAL FEATURE EXTRACTION FROM TEXT FIELDS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create similarity matrices using the titles\n",
    "corpus = info_all['title_str'].astype(str)\n",
    "\n",
    "norm_corpus = corpus_normalizer(corpus, how='stemming')\n",
    "n3gram_stem_title_sim_matrix, _ =  n3gram(norm_corpus, dataframe_ids=info_all['pm_id'])\n",
    "tfidf_stem_title_sim_matrix, _ = tfidf(norm_corpus, dataframe_ids=info_all['pm_id'])\n",
    "\n",
    "norm_corpus = corpus_normalizer(corpus, how='lemmatization')\n",
    "n3gram_lemma_title_sim_matrix, _ = n3gram(norm_corpus, dataframe_ids=info_all['pm_id'])\n",
    "tfidf_lemma_title_sim_matrix, _ = tfidf(norm_corpus, dataframe_ids=info_all['pm_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create similarity matrices using the authors\n",
    "corpus = info_all['authors_str'].fillna('').astype(str)\n",
    "\n",
    "ynorm_corpus = corpus_normalizer(corpus, how='stemming')\n",
    "n3gram_stem_author_sim_matrix, _ =  n3gram(norm_corpus, dataframe_ids=info_all['pm_id'])\n",
    "tfidf_stem_author_sim_matrix, _ = tfidf(norm_corpus, dataframe_ids=info_all['pm_id'])\n",
    "\n",
    "norm_corpus = corpus_normalizer(corpus, how='lemmatization')\n",
    "n3gram_lemma_author_sim_matrix, _ = n3gram(norm_corpus, dataframe_ids=info_all['pm_id'])\n",
    "tfidf_lemma_author_sim_matrix, _ = tfidf(norm_corpus, dataframe_ids=info_all['pm_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create similarity matrices using the abstracts\n",
    "corpus = info_all['abstract_str'].astype(str)\n",
    "\n",
    "norm_corpus = corpus_normalizer(corpus, how='stemming')\n",
    "tfidf_stem_abstract_sim_matrix, _ = tfidf(norm_corpus, dataframe_ids=info_all['pm_id'])\n",
    "\n",
    "norm_corpus = corpus_normalizer(corpus, how='lemmatization')\n",
    "tfidf_lemma_abstract_sim_matrix, _ = tfidf(norm_corpus, dataframe_ids=info_all['pm_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create similarity matrices concatenating all text fields\n",
    "corpus = (info_all['authors_str'].fillna('').astype(str) + ' ' +  info_all['title_str'].astype(str) + ' ' + \n",
    "          info_all['abstract_str'].astype(str) + ' ' + info_all['text_str'].fillna('').astype(str))\n",
    "\n",
    "norm_corpus = corpus_normalizer(corpus, how='stemming')\n",
    "tfidf_stem_all_strings_sim_matrix, _ = tfidf(norm_corpus, dataframe_ids=info_all['pm_id'])\n",
    "\n",
    "norm_corpus = corpus_normalizer(corpus, how='lemmatization')\n",
    "tfidf_lemma_all_strings_sim_matrix, _ = tfidf(norm_corpus, dataframe_ids=info_all['pm_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to retrief the similarity score for every pm_id and ref_id pair, in every similarity matrix\n",
    "def get_similarity_scores(matrices, data):\n",
    "    results = {}\n",
    "    for i, row in data.iterrows():\n",
    "        results[i] = []\n",
    "        for matrix in matrices:\n",
    "            results[i].append(matrix.at[row['pm_id'], row['ref_id']])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enriche the labeled dataframe with similarity scores\n",
    "sim_matrices = [n3gram_stem_title_sim_matrix, tfidf_stem_title_sim_matrix,\n",
    "                n3gram_lemma_title_sim_matrix, tfidf_lemma_title_sim_matrix,\n",
    "                n3gram_stem_author_sim_matrix, tfidf_stem_author_sim_matrix,\n",
    "                n3gram_lemma_author_sim_matrix, tfidf_lemma_author_sim_matrix,\n",
    "                tfidf_stem_abstract_sim_matrix, tfidf_lemma_abstract_sim_matrix,\n",
    "                tfidf_stem_all_strings_sim_matrix, tfidf_lemma_all_strings_sim_matrix]\n",
    "\n",
    "\n",
    "sim_scores_dict = get_similarity_scores(sim_matrices, data)\n",
    "\n",
    "sim_feature_names = ['n3gram_stem_title_sim_score', 'tfidf_stem_title_sim_score',\n",
    "                     'n3gram_lemma_title_sim_score', 'tfidf_lemma_title_sim_score',\n",
    "                     'n3gram_stem_author_sim_score', 'tfidf_stem_author_sim_score',\n",
    "                     'n3gram_lemma_author_sim_score', 'tfidf_lemma_author_sim_score',\n",
    "                     'tfidf_stem_abstract_sim_score', 'tfidf_lemma_abstract_sim_score',\n",
    "                     'tfidf_stem_all_strings_sim_score', 'tfidf_lemma_all_strings_sim_score']\n",
    "\n",
    "\n",
    "df_r = pd.DataFrame(sim_scores_dict, index=sim_feature_names).transpose()\n",
    "\n",
    "data = pd.concat([data, df_r], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________ all text based similarity features _______________________________\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm_id</th>\n",
       "      <th>ref_id</th>\n",
       "      <th>n3gram_stem_title_sim_score</th>\n",
       "      <th>tfidf_stem_title_sim_score</th>\n",
       "      <th>n3gram_lemma_title_sim_score</th>\n",
       "      <th>tfidf_lemma_title_sim_score</th>\n",
       "      <th>n3gram_stem_author_sim_score</th>\n",
       "      <th>tfidf_stem_author_sim_score</th>\n",
       "      <th>n3gram_lemma_author_sim_score</th>\n",
       "      <th>tfidf_lemma_author_sim_score</th>\n",
       "      <th>tfidf_stem_abstract_sim_score</th>\n",
       "      <th>tfidf_lemma_abstract_sim_score</th>\n",
       "      <th>tfidf_stem_all_strings_sim_score</th>\n",
       "      <th>tfidf_lemma_all_strings_sim_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17074820</td>\n",
       "      <td>15153999</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.221658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.298858</td>\n",
       "      <td>0.216477</td>\n",
       "      <td>0.313161</td>\n",
       "      <td>0.240701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17074820</td>\n",
       "      <td>15213210</td>\n",
       "      <td>0.086066</td>\n",
       "      <td>0.087672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.181894</td>\n",
       "      <td>0.154654</td>\n",
       "      <td>0.175891</td>\n",
       "      <td>0.146273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17074820</td>\n",
       "      <td>7668302</td>\n",
       "      <td>0.060858</td>\n",
       "      <td>0.059911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.198521</td>\n",
       "      <td>0.159695</td>\n",
       "      <td>0.181761</td>\n",
       "      <td>0.136338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17074820</td>\n",
       "      <td>12721363</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040751</td>\n",
       "      <td>0.046429</td>\n",
       "      <td>0.034123</td>\n",
       "      <td>0.036943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17074820</td>\n",
       "      <td>9096352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027104</td>\n",
       "      <td>0.030748</td>\n",
       "      <td>0.019998</td>\n",
       "      <td>0.022334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pm_id    ref_id  n3gram_stem_title_sim_score  \\\n",
       "0  17074820  15153999                     0.066667   \n",
       "1  17074820  15213210                     0.086066   \n",
       "2  17074820   7668302                     0.060858   \n",
       "3  17074820  12721363                     0.000000   \n",
       "4  17074820   9096352                     0.000000   \n",
       "\n",
       "   tfidf_stem_title_sim_score  n3gram_lemma_title_sim_score  \\\n",
       "0                    0.221658                           0.0   \n",
       "1                    0.087672                           0.0   \n",
       "2                    0.059911                           0.0   \n",
       "3                    0.000000                           0.0   \n",
       "4                    0.000000                           0.0   \n",
       "\n",
       "   tfidf_lemma_title_sim_score  n3gram_stem_author_sim_score  \\\n",
       "0                          0.0                           0.0   \n",
       "1                          0.0                           0.0   \n",
       "2                          0.0                           0.0   \n",
       "3                          0.0                           0.0   \n",
       "4                          0.0                           0.0   \n",
       "\n",
       "   tfidf_stem_author_sim_score  n3gram_lemma_author_sim_score  \\\n",
       "0                          0.0                            0.0   \n",
       "1                          0.0                            0.0   \n",
       "2                          0.0                            0.0   \n",
       "3                          0.0                            0.0   \n",
       "4                          0.0                            0.0   \n",
       "\n",
       "   tfidf_lemma_author_sim_score  tfidf_stem_abstract_sim_score  \\\n",
       "0                           0.0                       0.298858   \n",
       "1                           0.0                       0.181894   \n",
       "2                           0.0                       0.198521   \n",
       "3                           0.0                       0.040751   \n",
       "4                           0.0                       0.027104   \n",
       "\n",
       "   tfidf_lemma_abstract_sim_score  tfidf_stem_all_strings_sim_score  \\\n",
       "0                        0.216477                          0.313161   \n",
       "1                        0.154654                          0.175891   \n",
       "2                        0.159695                          0.181761   \n",
       "3                        0.046429                          0.034123   \n",
       "4                        0.030748                          0.019998   \n",
       "\n",
       "   tfidf_lemma_all_strings_sim_score  \n",
       "0                           0.240701  \n",
       "1                           0.146273  \n",
       "2                           0.136338  \n",
       "3                           0.036943  \n",
       "4                           0.022334  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observe created features\n",
    "neat_print_sperator('all text based similarity features')\n",
    "data[ids + sim_feature_names].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='34'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4) Combining features\n",
    "\n",
    "[Back to table of contents](#123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variable containing the total amount of members (pm-ids) for every set\n",
    "data['set_members_cnt'] = data['set_num'].map(data.groupby('set_num').agg('count')['pm_id'])\n",
    "data['real_set_members_cnt'] = data['set_members_cnt'].pow(1./2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm_id</th>\n",
       "      <th>ref_id</th>\n",
       "      <th>set_num</th>\n",
       "      <th>author_cnt_set_mean_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1624417</th>\n",
       "      <td>5812474</td>\n",
       "      <td>4169338</td>\n",
       "      <td>5</td>\n",
       "      <td>2.553785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120729</th>\n",
       "      <td>16513741</td>\n",
       "      <td>12761086</td>\n",
       "      <td>18</td>\n",
       "      <td>5.611413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1709430</th>\n",
       "      <td>4978744</td>\n",
       "      <td>4623313</td>\n",
       "      <td>5</td>\n",
       "      <td>2.553785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563296</th>\n",
       "      <td>1275890</td>\n",
       "      <td>4180276</td>\n",
       "      <td>5</td>\n",
       "      <td>2.553785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576496</th>\n",
       "      <td>6222136</td>\n",
       "      <td>3131772</td>\n",
       "      <td>5</td>\n",
       "      <td>2.553785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pm_id    ref_id  set_num  author_cnt_set_mean_enc\n",
       "1624417   5812474   4169338        5                 2.553785\n",
       "120729   16513741  12761086       18                 5.611413\n",
       "1709430   4978744   4623313        5                 2.553785\n",
       "1563296   1275890   4180276        5                 2.553785\n",
       "1576496   6222136   3131772        5                 2.553785"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create mean variable encodings per set\n",
    "to_set_mean_cols = [col for col in data.columns if (col.endswith('cnt') or col.endswith('flg')) and\n",
    "                                                         col not in ['is_referenced_flg', 'diff_pub_date_day_cnt']]\n",
    "\n",
    "for col in to_set_mean_cols:\n",
    "    name = re.sub('pm_', '', col)\n",
    "    name = name + '_set_mean_enc'\n",
    "    data[name] = data['set_num'].map(data.groupby('set_num').agg('mean')[col])\n",
    "    \n",
    "set_mean_cols = [re.sub('pm_', '', col) + '_set_mean_enc' for col in to_set_mean_cols]\n",
    "\n",
    "# Obseve for one feature\n",
    "example_cols = ids +['set_num'] + [set_mean_cols[0]]\n",
    "display(data.loc[data.set_num.isin([5,18]), example_cols].sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm_id</th>\n",
       "      <th>ref_id</th>\n",
       "      <th>set_num</th>\n",
       "      <th>author_cnt_set_mean_enc</th>\n",
       "      <th>pm_author_cnt</th>\n",
       "      <th>pm_author_cnt_diff_with_set_mean_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17074820</td>\n",
       "      <td>15153999</td>\n",
       "      <td>13</td>\n",
       "      <td>6.114679</td>\n",
       "      <td>3</td>\n",
       "      <td>3.114679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17074820</td>\n",
       "      <td>15213210</td>\n",
       "      <td>13</td>\n",
       "      <td>6.114679</td>\n",
       "      <td>3</td>\n",
       "      <td>3.114679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17074820</td>\n",
       "      <td>7668302</td>\n",
       "      <td>13</td>\n",
       "      <td>6.114679</td>\n",
       "      <td>3</td>\n",
       "      <td>3.114679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17074820</td>\n",
       "      <td>12721363</td>\n",
       "      <td>13</td>\n",
       "      <td>6.114679</td>\n",
       "      <td>3</td>\n",
       "      <td>3.114679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17074820</td>\n",
       "      <td>9096352</td>\n",
       "      <td>13</td>\n",
       "      <td>6.114679</td>\n",
       "      <td>3</td>\n",
       "      <td>3.114679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17074820</td>\n",
       "      <td>10788337</td>\n",
       "      <td>13</td>\n",
       "      <td>6.114679</td>\n",
       "      <td>3</td>\n",
       "      <td>3.114679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17074820</td>\n",
       "      <td>9114021</td>\n",
       "      <td>13</td>\n",
       "      <td>6.114679</td>\n",
       "      <td>3</td>\n",
       "      <td>3.114679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17074820</td>\n",
       "      <td>10330360</td>\n",
       "      <td>13</td>\n",
       "      <td>6.114679</td>\n",
       "      <td>3</td>\n",
       "      <td>3.114679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17074820</td>\n",
       "      <td>9634526</td>\n",
       "      <td>13</td>\n",
       "      <td>6.114679</td>\n",
       "      <td>3</td>\n",
       "      <td>3.114679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17074820</td>\n",
       "      <td>11466240</td>\n",
       "      <td>13</td>\n",
       "      <td>6.114679</td>\n",
       "      <td>3</td>\n",
       "      <td>3.114679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pm_id    ref_id  set_num  author_cnt_set_mean_enc  pm_author_cnt  \\\n",
       "0  17074820  15153999       13                 6.114679              3   \n",
       "1  17074820  15213210       13                 6.114679              3   \n",
       "2  17074820   7668302       13                 6.114679              3   \n",
       "3  17074820  12721363       13                 6.114679              3   \n",
       "4  17074820   9096352       13                 6.114679              3   \n",
       "5  17074820  10788337       13                 6.114679              3   \n",
       "6  17074820   9114021       13                 6.114679              3   \n",
       "7  17074820  10330360       13                 6.114679              3   \n",
       "8  17074820   9634526       13                 6.114679              3   \n",
       "9  17074820  11466240       13                 6.114679              3   \n",
       "\n",
       "   pm_author_cnt_diff_with_set_mean_enc  \n",
       "0                              3.114679  \n",
       "1                              3.114679  \n",
       "2                              3.114679  \n",
       "3                              3.114679  \n",
       "4                              3.114679  \n",
       "5                              3.114679  \n",
       "6                              3.114679  \n",
       "7                              3.114679  \n",
       "8                              3.114679  \n",
       "9                              3.114679  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate difference with mean set encodings for both pm- and ref-features\n",
    "pairs = []\n",
    "for i in range(0, len(to_set_mean_cols)):\n",
    "    pairs.append([set_mean_cols[i], to_set_mean_cols[i]])\n",
    "\n",
    "for pair in pairs:\n",
    "    name = pair[1] + '_diff_with_set_mean_enc'\n",
    "    data[name] = data[pair[0]] - data[pair[1]]\n",
    "    \n",
    "    if 'pm_' in pair[1]:\n",
    "        pair1 = re.sub('pm_', 'ref_', pair[1])\n",
    "        \n",
    "        name = pair1 + '_diff_with_set_mean_enc'\n",
    "        data[name] = data[pair[0]] - data[pair1]\n",
    "        \n",
    "diff_with_set_mean_cols = [col + '_diff_with_set_mean_enc' for col in to_set_mean_cols]\n",
    "\n",
    "# Obseve for one feature\n",
    "example_cols = ids + ['set_num', set_mean_cols[0], to_set_mean_cols[0], diff_with_set_mean_cols[0]]\n",
    "display(data[example_cols].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm_id</th>\n",
       "      <th>ref_id</th>\n",
       "      <th>set_num</th>\n",
       "      <th>pm_author_cnt</th>\n",
       "      <th>ref_author_cnt</th>\n",
       "      <th>diff_author_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>272288</th>\n",
       "      <td>6960359</td>\n",
       "      <td>4360942</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2101061</th>\n",
       "      <td>4945194</td>\n",
       "      <td>4945192</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221499</th>\n",
       "      <td>2162479</td>\n",
       "      <td>3548708</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689720</th>\n",
       "      <td>7048316</td>\n",
       "      <td>3905848</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190869</th>\n",
       "      <td>6097599</td>\n",
       "      <td>6321771</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pm_id   ref_id  set_num  pm_author_cnt  ref_author_cnt  \\\n",
       "272288   6960359  4360942       16              2               5   \n",
       "2101061  4945194  4945192        9              2               2   \n",
       "1221499  2162479  3548708        3              5               3   \n",
       "689720   7048316  3905848       16              2               3   \n",
       "190869   6097599  6321771       16              3               7   \n",
       "\n",
       "         diff_author_cnt  \n",
       "272288                -3  \n",
       "2101061                0  \n",
       "1221499                2  \n",
       "689720                -1  \n",
       "190869                -4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm_id</th>\n",
       "      <th>ref_id</th>\n",
       "      <th>pm_author_cnt</th>\n",
       "      <th>ref_author_cnt</th>\n",
       "      <th>diff_author_cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17074820</td>\n",
       "      <td>15153999</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17074820</td>\n",
       "      <td>15213210</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17074820</td>\n",
       "      <td>7668302</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17074820</td>\n",
       "      <td>12721363</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17074820</td>\n",
       "      <td>9096352</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pm_id    ref_id  pm_author_cnt  ref_author_cnt  diff_author_cnt\n",
       "0  17074820  15153999              3               0                3\n",
       "1  17074820  15213210              3               8               -5\n",
       "2  17074820   7668302              3               2                1\n",
       "3  17074820  12721363              3               7               -4\n",
       "4  17074820   9096352              3               8               -5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Take some differences between -pm and ref-features\n",
    "pm_cols = [col for col in data.columns if col.startswith('pm_') and  '_id' not in col\n",
    "           and not col.endswith('_set_mean_enc') and not col.endswith('_flg')] \n",
    "ref_cols = [col for col in data.columns if col.startswith('ref_') and  '_id' not in col\n",
    "            and not col.endswith('_set_mean_enc') and not col.endswith('_flg')]\n",
    "\n",
    "pairs = []\n",
    "for i in range(0, len(pm_cols)):\n",
    "    pairs.append([pm_cols[i], ref_cols[i]])\n",
    "\n",
    "for pair in pairs:\n",
    "    name = re.sub('pm_', 'diff_', pair[0])\n",
    "    data[name] = data[pair[0]] - data[pair[1]]\n",
    "        \n",
    "diff_cols = [re.sub('pm_', 'diff_', col) for col in pm_cols]\n",
    "\n",
    "# Obseve for one feature\n",
    "example_cols = ids + ['set_num', pm_cols[1], ref_cols[1], diff_cols[1]]\n",
    "display(data[example_cols].sample(5))\n",
    "\n",
    "example_cols = ids + [pm_cols[1], ref_cols[1], diff_cols[1]]\n",
    "display(data[example_cols].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm_id</th>\n",
       "      <th>ref_id</th>\n",
       "      <th>set_num</th>\n",
       "      <th>pm_author_mv_flg</th>\n",
       "      <th>ref_author_mv_flg</th>\n",
       "      <th>sum_author_mv_flg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17074820</td>\n",
       "      <td>15153999</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17074820</td>\n",
       "      <td>15213210</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17074820</td>\n",
       "      <td>7668302</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17074820</td>\n",
       "      <td>12721363</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17074820</td>\n",
       "      <td>9096352</td>\n",
       "      <td>13</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pm_id    ref_id  set_num  pm_author_mv_flg  ref_author_mv_flg  \\\n",
       "0  17074820  15153999       13             False               True   \n",
       "1  17074820  15213210       13             False              False   \n",
       "2  17074820   7668302       13             False              False   \n",
       "3  17074820  12721363       13             False              False   \n",
       "4  17074820   9096352       13             False              False   \n",
       "\n",
       "   sum_author_mv_flg  \n",
       "0                  1  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Take some sums of pm- and ref-flag-features\n",
    "pm_cols = [col for col in data.columns if col.startswith('pm_') and col.endswith('flg')] \n",
    "ref_cols = [col for col in data.columns if col.startswith('ref_') and col.endswith('flg')]\n",
    "\n",
    "pairs = []\n",
    "for i in range(0, len(pm_cols)):\n",
    "    pairs.append([pm_cols[i], ref_cols[i]])\n",
    "\n",
    "for pair in pairs:\n",
    "    name = re.sub('pm_', 'sum_', pair[0])\n",
    "    data[name] = data[pair[0]].astype(int) + data[pair[1]].astype(int)\n",
    "\n",
    "sum_cols = [re.sub('pm_', 'sum_', col) for col in pm_cols]\n",
    "    \n",
    "example_cols = ids + ['set_num', pm_cols[0], ref_cols[0], sum_cols[0]]\n",
    "\n",
    "# Obseve for one feature\n",
    "display(data[example_cols].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Data selection and partitioning\n",
    "\n",
    "[Back to table of contents](#123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns that temporary should be dropped and not be used for training, but are still useful afterwards\n",
    "to_drop = ids + ['set_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create different partitions for train and validations set\n",
    "train_sets = info_train.set_num.unique()[::2]\n",
    "val_sets = [s for s in info_train.set_num.unique() if s not in train_sets]\n",
    "\n",
    "# Use partitions to split the data\n",
    "X_train = data.loc[data.set_num.isin(train_sets), [col for col in data.columns if col != 'is_referenced_flg']]\n",
    "y_train = data.loc[data.set_num.isin(train_sets), 'is_referenced_flg']\n",
    "\n",
    "X_val = data.loc[data.set_num.isin(val_sets), [col for col in data.columns if col != 'is_referenced_flg']]\n",
    "y_val = data.loc[data.set_num.isin(val_sets), 'is_referenced_flg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Baseline modeling\n",
    "\n",
    "[Back to table of contents](#123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** SNIPPET FROM EARLY ON IN THE COMPETITION **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set steps of pipeline\n",
    "steps = [('ss', StandardScaler()),\n",
    "         ('lr', LogisticRegression(random_state=123))]\n",
    "\n",
    "# Chain pipeline into model\n",
    "bl_model = Pipeline(steps)\n",
    "\n",
    "# Train model\n",
    "bl_model.fit(X_train.drop(columns=to_drop), y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_proba = bl_model.predict_proba(X_train.drop(columns=to_drop))[:,1]\n",
    "y_val_pred_proba = bl_model.predict_proba(X_val.drop(columns=to_drop))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train roc auc: 0.9117\n",
      "val roc auc:   0.9250\n"
     ]
    }
   ],
   "source": [
    "# Observe general model performance\n",
    "print('train roc auc: {:.4f}'.format(roc_auc_score(y_train, y_train_pred_proba)))\n",
    "print('val roc auc:   {:.4f}'.format(roc_auc_score(y_val, y_val_pred_proba)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train f1:      0.1658\n",
      "val f1:        0.1914\n"
     ]
    }
   ],
   "source": [
    "# Observe general model performance\n",
    "y_train_pred = y_train_pred_proba > 0.5\n",
    "y_val_pred = y_val_pred_proba > 0.5\n",
    "\n",
    "print('train f1:      {:.4f}'.format(f1_score(y_train, y_train_pred)))\n",
    "print('val f1:        {:.4f}'.format(f1_score(y_val, y_val_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** HELPER FUCNTIONS FOR REAL EVALUATION **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions (in correct format)\n",
    "def pred_generator(df, threshold=0.5):\n",
    "    if sum(df['pred_proba'] > threshold) > 0:\n",
    "        to_return = str(list(df.loc[df['pred_proba'] > threshold, 'ref_id'].astype(str)))\n",
    "    else:\n",
    "        to_return = str([df.loc[df['pred_proba'].idxmax(), 'ref_id'].astype(str)])\n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________ model output __________________________________________\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm_id</th>\n",
       "      <th>ref_id</th>\n",
       "      <th>pred_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17074820</td>\n",
       "      <td>15153999</td>\n",
       "      <td>0.145136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17074820</td>\n",
       "      <td>15213210</td>\n",
       "      <td>0.020658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17074820</td>\n",
       "      <td>7668302</td>\n",
       "      <td>0.052667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17074820</td>\n",
       "      <td>12721363</td>\n",
       "      <td>0.004583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17074820</td>\n",
       "      <td>9096352</td>\n",
       "      <td>0.007041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pm_id    ref_id  pred_proba\n",
       "0  17074820  15153999    0.145136\n",
       "1  17074820  15213210    0.020658\n",
       "2  17074820   7668302    0.052667\n",
       "3  17074820  12721363    0.004583\n",
       "4  17074820   9096352    0.007041"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________ predictions __________________________________________\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm_id</th>\n",
       "      <th>ref_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17074820</td>\n",
       "      <td>['15153999']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15153999</td>\n",
       "      <td>['17074820']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15213210</td>\n",
       "      <td>['1539589']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7668302</td>\n",
       "      <td>['1539589']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12721363</td>\n",
       "      <td>['11842208', '12486239', '7942858']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pm_id                             ref_list\n",
       "0  17074820                         ['15153999']\n",
       "1  15153999                         ['17074820']\n",
       "2  15213210                          ['1539589']\n",
       "3   7668302                          ['1539589']\n",
       "4  12721363  ['11842208', '12486239', '7942858']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________________ original ____________________________________________\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm_id</th>\n",
       "      <th>ref_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17074820</td>\n",
       "      <td>['15153999', '15213210', '7668302']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15153999</td>\n",
       "      <td>['12721363', '9096352', '10788337', '9114021',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15213210</td>\n",
       "      <td>['11466240', '12184798']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7668302</td>\n",
       "      <td>['1539589']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12721363</td>\n",
       "      <td>['9465087', '11842208', '11309498', '9465125',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pm_id                                           ref_list\n",
       "0  17074820                ['15153999', '15213210', '7668302']\n",
       "1  15153999  ['12721363', '9096352', '10788337', '9114021',...\n",
       "2  15213210                           ['11466240', '12184798']\n",
       "3   7668302                                        ['1539589']\n",
       "4  12721363  ['9465087', '11842208', '11309498', '9465125',..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create dataframe with predictions of model\n",
    "predictions = X_train[['pm_id', 'ref_id']].copy()\n",
    "predictions['pred_proba'] = y_train_pred_proba\n",
    "\n",
    "neat_print_sperator('model output')\n",
    "display(predictions.head())\n",
    "\n",
    "# Apply the helper function\n",
    "predictions = predictions.groupby('pm_id').apply(pred_generator).to_frame()\n",
    "predictions = predictions.reset_index().rename(columns={0: 'ref_list'})\n",
    "\n",
    "# Get order of pm ids in original data\n",
    "correct_order = info_train.loc[info_train.set_num.isin(train_sets), ['pm_id', 'set_num']]\n",
    "\n",
    "# Give predictions the same order\n",
    "predictions = pd.merge(correct_order, predictions, on='pm_id')\n",
    "\n",
    "# Compare\n",
    "neat_print_sperator('predictions')\n",
    "display(predictions.drop(columns='set_num').head())\n",
    "\n",
    "neat_print_sperator('original')\n",
    "display(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate input for f1 scorer\n",
    "def f1_input_generator(y, ys):\n",
    "    to_return = []\n",
    "    for i in sorted(set(ys)):\n",
    "        if i in y:\n",
    "            to_return.append(1)\n",
    "        else:\n",
    "            to_return.append(0)\n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true:       [1, 3]\n",
      "y_pred:       [1, 4]\n",
      "labels:       [1, 3, 4]\n",
      "y_true_input: [1, 1, 0]\n",
      "y_pred_input: [1, 0, 1]\n",
      "F1 score:     0.5\n"
     ]
    }
   ],
   "source": [
    "# Set some dummy predictions\n",
    "y_true = [1,3]\n",
    "y_pred = [1,4]\n",
    "\n",
    "# Get input for F1_score\n",
    "y_true_input = f1_input_generator(y_true, y_true + y_pred)\n",
    "y_pred_input = f1_input_generator(y_pred, y_true + y_pred)\n",
    "\n",
    "score = f1_score(y_true_input, y_pred_input, average='binary')\n",
    "\n",
    "# Show\n",
    "print('y_true:      ', y_true)\n",
    "print('y_pred:      ', y_pred)\n",
    "print('labels:      ', sorted(set(y_true + y_pred)))\n",
    "print('y_true_input:', y_true_input)\n",
    "print('y_pred_input:', y_pred_input)\n",
    "print('F1 score:    ', score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** PUTTING IT ALL TOGETHER **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_scores(X, pred_proba, sets):\n",
    "    predictions = X[['pm_id', 'ref_id']].copy()\n",
    "    predictions['pred_proba'] = pred_proba\n",
    "    predictions = predictions.groupby('pm_id').apply(pred_generator).to_frame()\n",
    "    predictions = predictions.reset_index().rename(columns={0: 'ref_list'})\n",
    "    \n",
    "    correct_order = info_train.loc[info_train.set_num.isin(sets), ['pm_id', 'set_num']]\n",
    "    predictions = pd.merge(correct_order, predictions, on='pm_id')\n",
    "\n",
    "    actuals = pd.merge(correct_order, train, on='pm_id')\n",
    "    scores = {}\n",
    "    for set_n in predictions.set_num.unique():\n",
    "        scores[set_n] = []\n",
    "        for i, row in predictions.loc[predictions.set_num == set_n, :].iterrows():\n",
    "            y_true = ast.literal_eval(actuals.loc[i, 'ref_list'])\n",
    "            y_pred = ast.literal_eval(row['ref_list'])\n",
    "\n",
    "            y_true_input = f1_input_generator(y_true, y_true + y_pred)\n",
    "            y_pred_input = f1_input_generator(y_pred, y_true + y_pred)\n",
    "\n",
    "            score = f1_score(y_true_input, y_pred_input, average='binary')\n",
    "\n",
    "            scores[set_n].append(score)\n",
    "\n",
    "    mean_scores = {}\n",
    "    for set_n in predictions.set_num.unique():\n",
    "        mean_scores[set_n] = np.mean(scores[set_n])\n",
    "    \n",
    "    df = pd.Series(mean_scores).to_frame().rename(columns={0: 'mean f1 scores'})\n",
    "    df.index.name = 'set_num'\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________ training: 0.2503 ________________________________________\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean f1 scores</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set_num</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.194999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.268413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.353517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.246834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.187599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mean f1 scores\n",
       "set_num                \n",
       "3              0.194999\n",
       "5              0.268413\n",
       "6              0.353517\n",
       "13             0.246834\n",
       "16             0.187599"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________________ validation: 0.2730 _______________________________________\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean f1 scores</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set_num</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.355639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.207172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.219899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.309300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         mean f1 scores\n",
       "set_num                \n",
       "2              0.355639\n",
       "8              0.207172\n",
       "14             0.219899\n",
       "18             0.309300"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get mean f1 scores and take overall score\n",
    "train_scores = get_f1_scores(X_train, y_train_pred_proba, train_sets)\n",
    "neat_print_sperator('{}: {:0.4f}'.format('training', train_scores.mean().values[0]))\n",
    "display(train_scores)\n",
    "\n",
    "val_scores = get_f1_scores(X_val, y_val_pred_proba, val_sets)\n",
    "neat_print_sperator('{}: {:0.4f}'.format('validation', val_scores.mean().values[0]))\n",
    "display(val_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='6'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 6) Spotchecking\n",
    "\n",
    "[Back to table of contents](#123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate classifiers\n",
    "classifiers = [\n",
    "#                ('KNeighborsClassifier', KNeighborsClassifier()),\n",
    "#                ('RadiusNeighborsClassifier', RadiusNeighborsClassifier(radius=5)),\n",
    "               \n",
    "#                ('PassiveAggressiveClassifier', PassiveAggressiveClassifier(random_state=123)),\n",
    "#                ('Perceptron', Perceptron(random_state=123)),\n",
    "#                ('RidgeClassifier', RidgeClassifier(random_state=123)),\n",
    "#                ('LogisticRegression', LogisticRegression(random_state=123, n_jobs=-1)),\n",
    "               ('SGDClassifier', SGDClassifier(random_state=123, n_jobs=-1)),\n",
    "               \n",
    "#                ('LinearSVC', LinearSVC()),\n",
    "#                ('NuSVC', NuSVC()),\n",
    "#                ('SVC', SVC()),\n",
    "               \n",
    "               ('AdaBoostClassifier', AdaBoostClassifier(random_state=123)),\n",
    "               ('ExtraTreesClassifier', ExtraTreesClassifier(random_state=123, n_jobs=-1)),\n",
    "               ('GradientBoostingClassifier', GradientBoostingClassifier(random_state=123)),\n",
    "               ('RandomForestClassifier', RandomForestClassifier(random_state=123, n_jobs=-1)),\n",
    "               \n",
    "               ('MLPClassifier', MLPClassifier(random_state=123)),\n",
    "               \n",
    "#                ('DecisionTreeClassifier', DecisionTreeClassifier(random_state=123)),\n",
    "#                ('ExtraTreeClassifier', ExtraTreeClassifier(random_state=123)),\n",
    "               \n",
    "#                ('LinearDiscriminantAnalysis', LinearDiscriminantAnalysis()),\n",
    "#                ('QuadraticDiscriminantAnalysis', QuadraticDiscriminantAnalysis()),\n",
    "               \n",
    "#                ('BernoulliNB', BernoulliNB()),\n",
    "#                ('GaussianNB', GaussianNB()),\n",
    "#                ('MultinomialNB', MultinomialNB()),\n",
    "               \n",
    "#                ('GaussianProcessClassifier', GaussianProcessClassifier(random_state=123, n_jobs=-1))\n",
    "              ]\n",
    "\n",
    "# Put classifiers in a series object\n",
    "clfs = pd.Series()\n",
    "for clf_name, clf in classifiers:\n",
    "    clfs[clf_name] = clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier done fitting and predicting\n",
      "AdaBoostClassifier done fitting and predicting\n",
      "ExtraTreesClassifier done fitting and predicting\n",
      "GradientBoostingClassifier done fitting and predicting\n",
      "RandomForestClassifier done fitting and predicting\n",
      "MLPClassifier done fitting and predicting\n"
     ]
    }
   ],
   "source": [
    "# Get spotcheking results\n",
    "spch_preds = {}\n",
    "for i, clf_name in enumerate(clfs.index):\n",
    "    \n",
    "#     t1 = time.time()\n",
    "    \n",
    "    steps = [('ss', StandardScaler()), (clf_name, clfs[clf_name])]\n",
    "    spch_model = Pipeline(steps)\n",
    "    spch_model.fit(X_train.drop(columns=to_drop), y_train)\n",
    "    \n",
    "    try:\n",
    "        y_train_spch_pred = spch_model.predict_proba(X_train.drop(columns=to_drop))[:,1]\n",
    "        y_val_spch_pred = spch_model.predict_proba(X_val.drop(columns=to_drop))[:,1]\n",
    "         \n",
    "    except:\n",
    "        y_train_spch_pred = spch_model.predict(X_train.drop(columns=to_drop))\n",
    "        y_val_spch_pred = spch_model.predict(X_val.drop(columns=to_drop))\n",
    "        \n",
    "    t2 = time.time()\n",
    "    \n",
    "#     print('{} done in {:.0f}s'.format(clf_name, t2 - t1))\n",
    "    print('{} done fitting and predicting'.format(clf_name))\n",
    "    \n",
    "    spch_preds[clf_name] = [y_train_spch_pred, y_val_spch_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_roc_auc</th>\n",
       "      <th>val_roc_auc</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>val_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.9587</td>\n",
       "      <td>0.9485</td>\n",
       "      <td>0.2862</td>\n",
       "      <td>0.3226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.9566</td>\n",
       "      <td>0.9507</td>\n",
       "      <td>0.3024</td>\n",
       "      <td>0.2754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.5736</td>\n",
       "      <td>0.6063</td>\n",
       "      <td>0.2137</td>\n",
       "      <td>0.2441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8588</td>\n",
       "      <td>0.9177</td>\n",
       "      <td>0.2365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPClassifier</th>\n",
       "      <td>0.9650</td>\n",
       "      <td>0.8867</td>\n",
       "      <td>0.3360</td>\n",
       "      <td>0.2032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8119</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.1127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            train_roc_auc  val_roc_auc  train_f1  val_f1\n",
       "AdaBoostClassifier                 0.9587       0.9485    0.2862  0.3226\n",
       "GradientBoostingClassifier         0.9566       0.9507    0.3024  0.2754\n",
       "SGDClassifier                      0.5736       0.6063    0.2137  0.2441\n",
       "RandomForestClassifier             1.0000       0.8588    0.9177  0.2365\n",
       "MLPClassifier                      0.9650       0.8867    0.3360  0.2032\n",
       "ExtraTreesClassifier               1.0000       0.8119    1.0000  0.1127"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observe model performance\n",
    "spch_scores = {}\n",
    "for clf_name, preds in spch_preds.items():\n",
    "    spch_scores[clf_name] = [roc_auc_score(y_train, preds[0]), roc_auc_score(y_val, preds[1])]\n",
    "    spch_scores[clf_name] += [f1_score(y_train, preds[0] > 0.5), f1_score(y_val, preds[1] > 0.5)]\n",
    "    \n",
    "df = pd.DataFrame.from_dict(spch_scores, orient='index')\n",
    "df.columns = ['train_roc_auc', 'val_roc_auc', 'train_f1', 'val_f1']\n",
    "df = df.sort_values('val_f1', ascending=False)\n",
    "df.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_f1_score</th>\n",
       "      <th>mean_val_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <td>0.3430</td>\n",
       "      <td>0.3839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.3618</td>\n",
       "      <td>0.3717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPClassifier</th>\n",
       "      <td>0.3510</td>\n",
       "      <td>0.3485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.9365</td>\n",
       "      <td>0.3136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>0.9981</td>\n",
       "      <td>0.2490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.2011</td>\n",
       "      <td>0.1968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            mean_train_f1_score  mean_val_f1_score\n",
       "AdaBoostClassifier                       0.3430             0.3839\n",
       "GradientBoostingClassifier               0.3618             0.3717\n",
       "MLPClassifier                            0.3510             0.3485\n",
       "RandomForestClassifier                   0.9365             0.3136\n",
       "ExtraTreesClassifier                     0.9981             0.2490\n",
       "SGDClassifier                            0.2011             0.1968"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate real performance\n",
    "eval_results= {}\n",
    "for clf in spch_preds.keys():\n",
    "    train_scores = get_f1_scores(X_train, spch_preds[clf][0], train_sets)\n",
    "    val_scores = get_f1_scores(X_val, spch_preds[clf][1], val_sets)\n",
    "    \n",
    "    mean_train_score = round(train_scores.mean().values[0],4)\n",
    "    mean_val_score = round(val_scores.mean().values[0], 4)\n",
    "    \n",
    "    eval_results[clf] = [mean_train_score, mean_val_score]\n",
    "    \n",
    "df = pd.DataFrame.from_dict(eval_results).transpose()\n",
    "df.columns = ['mean_train_f1_score', 'mean_val_f1_score']\n",
    "df = df.sort_values('mean_val_f1_score', ascending=False)\n",
    "df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='7'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Submission\n",
    "\n",
    "[Back to table of contents](#123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit final model on all training data\n",
    "X = data.loc[~data.is_referenced_flg.isnull(), [col for col in data.columns if col != 'is_referenced_flg']]\n",
    "y = data.loc[~data.is_referenced_flg.isnull(), 'is_referenced_flg']\n",
    "\n",
    "X_ulbld = data.loc[data.is_referenced_flg.isnull(), [col for col in data.columns if col != 'is_referenced_flg']]\n",
    "\n",
    "steps = [('ss', StandardScaler()),\n",
    "         ('abc', AdaBoostClassifier(random_state=123))]\n",
    "\n",
    "final_model = Pipeline(steps)\n",
    "\n",
    "final_model.fit(X.drop(columns=to_drop), y)\n",
    "\n",
    "pred_proba = final_model.predict_proba(X_ulbld.drop(columns=to_drop))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>ref_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14058267</td>\n",
       "      <td>['13814573']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4550818</td>\n",
       "      <td>['14273645']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14222809</td>\n",
       "      <td>['13885712', '14381435', '13398435', '14381436...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4164675</td>\n",
       "      <td>['14176294']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6211173</td>\n",
       "      <td>['6451217', '6211171']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pmid                                           ref_list\n",
       "0  14058267                                       ['13814573']\n",
       "1   4550818                                       ['14273645']\n",
       "2  14222809  ['13885712', '14381435', '13398435', '14381436...\n",
       "3   4164675                                       ['14176294']\n",
       "4   6211173                             ['6451217', '6211171']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2,034; 2)\n"
     ]
    }
   ],
   "source": [
    "# Create predictions\n",
    "predictions = X_ulbld[['pm_id', 'ref_id']].copy()\n",
    "predictions['pred_proba'] = pred_proba\n",
    "predictions = predictions.groupby('pm_id').apply(pred_generator).to_frame()\n",
    "predictions = predictions.reset_index().rename(columns={0: 'ref_list'})\n",
    "\n",
    "correct_order = test[['pm_id']]\n",
    "predictions = pd.merge(correct_order, predictions, on='pm_id')\n",
    "predictions = predictions.rename(columns={'pm_id': 'pmid'})\n",
    "display(predictions.head())\n",
    "print('shape: ({:,}; {:})'.format(dataset.shape[0], dataset.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create \"bumission\" file\n",
    "predictions.to_csv(r'Data\\Submissions\\final bumission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check performance of final \"bumission\"\n",
    "Image('final bumission.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='8'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8) Reflection\n",
    "\n",
    "[Back to table of contents](#123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"justify\">First off, I could have manged my time better, haha. Of course, if I had made my final submission a bit earlier I would not be saying this. However, from a performance point of view I put a bit too much effort in engineering features. Because at the end I had no time to do any fancy modeling. I spot checked only a hand full of models, performed no hyperparameter tuning, or any grid search of that kind, I did not stack any models into a neat ensemble and I also did not tune the tren-hold (#Mike again). Whereas the problem setup absolutely lends itself to this, as every set could be used as a cross-validation-fold. On top of that, I still left a lot of feature generation possibilities to boost tree-based model performance untouched: like frequency encodings, mean-target encodings, feature rankings etc. So, there is still plenty of room to boost the performance of the current model.</div><br>\n",
    "\n",
    "<div align=\"justify\">Near the deadline of the competition I noticed that some of the full texts contained references inside them, I was not able to fully investigate and exploit this, but I decided to run a tfidf on the concatenation of the full text and the authors, which ended up working very well. Moreover, there was no need to construct a test set for this problem as it was clearly communicated how the public part of the leader board was made. Hence, competitors knew for a fact that the predictions scores on the public leader board would be representative for the performance. In many competitions this is not the case. The public part of the leader board is often formed by a random split, making it unbalanced and pretty much useless, unless for leader board probing of course. Anyway, I am a firm believer of not making too many submissions as it will just lead to plain overfitting. Furthermore, a well-constructed validation scheme should give sufficient feedback (or no validation scheme at all in my case).</div><br>\n",
    "\n",
    "<div align=\"justify\">To wrap up, some minor things that could be improved: I think Innoplexus could have put more effort in explaining the evaluation metric, as I had a hard time figuring this out (and so did others apparently) – it might be more convenient to give a formula, or at least some more examples. Next, I would very much like Analytics Vidhya to make discussions more accessible and code sharing mandatory or at least easier. Anyway, I am just nit-picking. I really enjoyed this experience. I would like to thank them both, Innoplexus for the challenging problem, Analytics Vidhya for the great hacking experience – AND you for competing!</div><br>\n",
    "\n",
    "<div>– Eat clean & mine dirty –  #Rich Piana</div><br><br><br><br>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
